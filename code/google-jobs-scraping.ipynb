{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1830,
   "id": "af6cc60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import regex as re\n",
    "from copy import deepcopy \n",
    "import random\n",
    "import datetime as dt\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0345e128",
   "metadata": {},
   "source": [
    "## Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1831,
   "id": "b78a48cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url filters: jobs posted within past day, within 15 miles of New York, NY\n",
    "google_jobs_url = 'https://www.google.com/search?q=jobs&oq=google+jobs+data+analyst&aqs=chrome..69i57j69i59j0i512j0i22i30i625l4j69i60.4543j0j7&sourceid=chrome&ie=UTF-8&ibp=htl;jobs&sa=X&ved=2ahUKEwjXsv-_iZP9AhVPRmwGHX5xDEsQutcGKAF6BAgPEAU&sxsrf=AJOqlzWGHNISzgpAUCZBmQA1mWXXt3I7gA:1676311105893#fpstate=tldetail&htivrt=jobs&htichips=city:Owg_06VPwoli_nfhBo8LyA%3D%3D,date_posted:today&htischips=city;Owg_06VPwoli_nfhBo8LyA%3D%3D:New%20York_comma_%20NY,date_posted;today&htilrad=24.1401&htidocid=9dwQD_uVzp1Nu-9BAAAAAA%3D%3D'\n",
    "# path to CSV where google jobs dataset will be held\n",
    "descr_df_path = '/Users/ravram/Desktop/pay-transparency/data/output/google-jobs-cronjob.csv' # need to change path when put on server\n",
    "# path to CSV where extra column data will be held\n",
    "scroll_df_path = '/Users/ravram/Desktop/pay-transparency/data/output/google-jobs-extra-cols-cronjob.csv' # need to change path when put on server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1921,
   "id": "5bee8b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomizing user agent from list found at https://github.com/udger/test-data/blob/master/CSV_data_example/userAgent_client_hints.csv\n",
    "# trying to prevent banning/ limiting\n",
    "\n",
    "ua_file = pd.read_csv('/Users/ravram/Desktop/pay-transparency/data/input/userAgent_client_hints.csv').rename(columns={'1':'User Agent'})\n",
    "\n",
    "def get_random_ua(ua_df):\n",
    "    \n",
    "    random_num = random.choice(list(range(0,12)))\n",
    "    user_agent = ua_df['User Agent'].loc[random_num]\n",
    "    \n",
    "    return user_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1934,
   "id": "9193679d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that scrapes data from Google Jobs\n",
    "\n",
    "def scrape_google_jobs(url, scroll_path_location, descr_path_location, postings):\n",
    "    \n",
    "# url: web url to the google jobs page that will be scraped (str)\n",
    "# scroll_path_location: path to the CSV file where the data scraped from the scroll section of Google Jobs will be stored (str)\n",
    "# descr_path_location: path to the CSV file where the data scraped from the job description section of Google Jobs will be stored (str)\n",
    "# postings: number of job postings to be scraped -> can be increased by increments of 10 starting at 20, going up to limit of 150 (int)\n",
    "    \n",
    "    options = Options() # preparing to run in headless browser\n",
    "    options.add_argument('headless') \n",
    "\n",
    "    # using sing selenium to launch and scroll through the Google Jobs page\n",
    "    url = url\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    \n",
    "    user_agent = get_random_ua(ua_file) #driver.execute_script(\"return navigator.userAgent;\")\n",
    "    user_agent = user_agent.replace(\"HeadlessChrome\",\"Chrome\")\n",
    "    driver.execute_cdp_cmd('Network.setUserAgentOverride',{\"userAgent\": f'{user_agent}'})\n",
    "    \n",
    "    driver.get(url)\n",
    "    \n",
    "    # column names and paths to desired data on scroll section of website\n",
    "    xpaths_scr = {\n",
    "         'Role'            :\"./div[2]\",\n",
    "         'Company'         :\"./div[4]/div/div[1]\",\n",
    "         'Source'          :\"./div[4]/div/div[3]\",\n",
    "         'Full / Part Time':\".//*[name()='path'][contains(@d,'M20 6')]/ancestor::div[1]\",\n",
    "        }\n",
    "    \n",
    "    scrolls_to_do = postings # setting number of job postings to be scraped\n",
    "    scrolls_done = 0\n",
    "    data_scr = {key:[] for key in xpaths_scr} # data will be added to this dict\n",
    "    \n",
    "    # stay in while loop until desired number of postings have been scrolled to\n",
    "    while scrolls_done < scrolls_to_do: \n",
    "        lis_scr = driver.find_elements(By.XPATH, \"//li[@data-ved]//div[@role='treeitem']/div/div\") # path to section of page where user can scroll through job postings \n",
    "\n",
    "        if (len(lis_scr) == scrolls_done) and (scrolls_to_do - scrolls_done) > 0: # in case the postings variable exceeds number of available job posting entries (otherwise code will be stuck in infinite loop)\n",
    "        \n",
    "            # print('\\nNote: requested # of postings greater than available postings')\n",
    "            scrolls_to_do = len(lis_scr) # resetting scrolls_to_do to the max length of lis_scr so can break out of while loop\n",
    "            \n",
    "        # scrolling down the page to make desired number of job postings load, therefore making them accessible for scraping\n",
    "        for li_scr in lis_scr[scrolls_done:]:\n",
    "            driver.execute_script('arguments[0].scrollIntoView({block: \"center\", behavior: \"smooth\"});', li_scr) \n",
    "\n",
    "            for key in xpaths_scr:\n",
    "                try: # pull data at each path in the xpaths dict for each job posting\n",
    "                    t = li_scr.find_element(By.XPATH, xpaths_scr[key]).get_attribute('innerText')\n",
    "                except NoSuchElementException: # if can't find, indicate with text\n",
    "                    t = '*missing data*'\n",
    "                    \n",
    "                data_scr[key].append(t) # add to data dict\n",
    "            \n",
    "            scrolls_done += 1\n",
    "            print(f'{scrolls_done=}', end='\\r') # to visualize how many scrolls have been performed\n",
    "            time.sleep(.2)    \n",
    "            \n",
    "    scr_scraped_df = pd.DataFrame(data_scr) # convert to df\n",
    "    \n",
    "    print('')\n",
    "    \n",
    "    ####\n",
    "    \n",
    "    # column names and paths to desired data in job description page section of website\n",
    "    xpaths_descr = { \n",
    "         'Role'               :\"./div/div[1]/div/div[1]/h2\",\n",
    "         'Company'            :\"./div/div[1]/div/div[2]/div[2]/div[1]\",\n",
    "         'Location'           :\"./div/div[1]/div/div[2]/div[2]/div[2]\",\n",
    "         'Posted'             :\"./div/div[3]/div[1]/span[2]/span\",\n",
    "         'All Sources Listed' :\".//div[@class='B8oxKe BQC79e xXyUwe']\",\n",
    "         'Scraped Salary'     :\".//span[@class='LL4CDc' and contains(@aria-label,'Salary')]/span\",\n",
    "         'Job Highlights'     :\"./div/div[4]/div[1]/div[2]/g-expandable-container/div/g-expandable-content[2]/span\",\n",
    "         'Job Description'    :\"./div/div[5]/div/span\",\n",
    "         'Any Other Text'     :\"./div/div[4]\" \n",
    "        }\n",
    "    \n",
    "    descr_done = 0\n",
    "    data_descr = {key:[] for key in xpaths_descr} # data will be added to this dict\n",
    "    data_descr['Date Scraped'] = []\n",
    "    \n",
    "    lis_descr = driver.find_elements(By.XPATH, \"//*[@id='gws-plugins-horizon-jobs__job_details_page']\") # path to description page for each job \n",
    "    \n",
    "    for li_descr in lis_descr[0:scrolls_to_do]: # looping through desired number of job description pages\n",
    "    \n",
    "        for key in xpaths_descr:\n",
    "\n",
    "            try: # pull data at each path in the xpaths dict for each job posting\n",
    "                t = li_descr.find_element(By.XPATH, xpaths_descr[key]).get_attribute('innerText')\n",
    "            except NoSuchElementException: # if can't find, indicate with text\n",
    "                t = '*missing data*'\n",
    "            if t == '': # in cases where element exists but is just ''\n",
    "                t='*missing data*'\n",
    "                \n",
    "            data_descr[key].append(t) # add to data dict\n",
    "            \n",
    "        data_descr['Date Scraped'].append(dt.datetime.now()) # adding date scraped\n",
    "            \n",
    "        descr_done += 1\n",
    "        print(f'{descr_done=}', end='\\r') # to visualize how many description pages have been scraped\n",
    "        time.sleep(.2)\n",
    "        \n",
    "    descr_scraped_df = pd.DataFrame(data_descr) # convert to df\n",
    "    \n",
    "    for ind in descr_scraped_df.index: # Any Other Text collects full text for posting... only worth keeping if Job Highlights and Description are both empty, otherwise redundant info just taking up space\n",
    "        \n",
    "        if (descr_scraped_df['Job Highlights'][ind] != '*missing data*') or (descr_scraped_df['Job Description'][ind] != '*missing data*'):\n",
    "            \n",
    "            descr_scraped_df.loc[ind, 'Any Other Text'] = np.nan # erasing this text if either Job Highlights or Job Description is present\n",
    "    \n",
    "    scr_path = scroll_path_location \n",
    "    \n",
    "    if os.path.exists(scr_path): # if CSV already exists at the specified path, add the new data found in scr_scraped_df\n",
    "        scr_original_df = pd.read_csv(scr_path) # convert existing CSV to df\n",
    "        scr_original_df = pd.concat([scr_original_df,scr_scraped_df]) # add new data\n",
    "        scr_original_df = scr_original_df.drop_duplicates() # drop entries with identical data \n",
    "        scr_original_df.to_csv(scr_path, index = False) # redownloading updated df to the specified path\n",
    "    else: # otherwise, create new file at this path (for first time function is run)\n",
    "        scr_scraped_df.to_csv(scr_path, index = False) \n",
    "        \n",
    "    descr_path = descr_path_location \n",
    "    \n",
    "    if os.path.exists(descr_path): # if CSV already exists at the specified path, add the new data found in descr_scraped_df \n",
    "        descr_original_df = pd.read_csv(descr_path) # convert existing CSV to df\n",
    "        descr_original_df = pd.concat([descr_original_df,descr_scraped_df]) # add new data\n",
    "        # drop entries with identical data in these columns... leaving Posted and All Sources Listed out of this in case duplicates are posted at dif times/ from dif sites\n",
    "        descr_original_df = descr_original_df.drop_duplicates(subset=['Role','Company','Location','Scraped Salary','Job Highlights','Job Description', 'Any Other Text']) \n",
    "        descr_original_df.to_csv(descr_path, index = False) # redownloading updated df to the specified path\n",
    "    else: # otherwise, create new file at this path (for first time function is run)\n",
    "        descr_scraped_df.to_csv(descr_path, index = False)  \n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1935,
   "id": "d19cd052",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrolls_done=30\n",
      "descr_done=30\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Mozilla/5.0 (Macintosh; Intel Mac OS X 11_1_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.192 Safari/537.36'"
      ]
     },
     "execution_count": 1935,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrape_google_jobs(google_jobs_url, scroll_df_path, descr_df_path, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1b064f",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1474,
   "id": "60942e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that cleans values in 'Source' and 'All Sources Listed' columns\n",
    "# called by add_columns()\n",
    "\n",
    "def clean_sources(df):\n",
    "    \n",
    "# df: df containing all of the compiled google jobs data (DataFrame)\n",
    "    \n",
    "    # replacing non-Source text with '*' (not likely any source names will contain this character)\n",
    "    df['All Sources Listed'] = df['All Sources Listed'].fillna('')\n",
    "    df['All Sources Listed'] = df['All Sources Listed'].str.replace('Apply on ','*') \n",
    "    df['All Sources Listed'] = df['All Sources Listed'].str.replace('Apply directly on ','*')\n",
    "    \n",
    "    #splitting on '*' to separate each source in a list\n",
    "    df['All Sources Listed'] = df['All Sources Listed'].str.split('*')\n",
    "    \n",
    "    for ind in df.index: # removing any remaining spaces\n",
    "\n",
    "        if '' in df['All Sources Listed'][ind]: df['All Sources Listed'][ind].remove('')\n",
    "        if df['All Sources Listed'][ind] == []: df['All Sources Listed'][ind] = np.nan # replacing empty lists with NaN\n",
    "            \n",
    "    df['Source'] = df['Source'].str.replace('via ','') # removing 'via' from Source column values to isolate source name\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1475,
   "id": "308869b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that adds columns from google_jobs_scr_df to google_jobs_descr_df based on unique job keys\n",
    "# to be run after final dataset is compiled\n",
    "\n",
    "def add_columns(google_jobs_descr_df, google_jobs_scr_df):\n",
    "    \n",
    "# google_jobs_descr_df: df containing all of the data from the job description page scrape (DataFrame)\n",
    "# google_jobs_scr_df: df containing the columns from the Google Jobs scroll section to be added to google_jobs_descr_df (DataFrame)\n",
    "\n",
    "    # initializing empty dicts\n",
    "    source_dict = {}\n",
    "    time_dict = {}\n",
    "    \n",
    "    for ind in google_jobs_scr_df.index: \n",
    "    \n",
    "        col_key = google_jobs_scr_df['Role'][ind] + google_jobs_scr_df['Company'][ind] # create unique job key (title and company combined)\n",
    "        \n",
    "        source_dict[col_key] = google_jobs_scr_df['Source'][ind] # add Source data as value associated with job key\n",
    "        time_dict[col_key] = google_jobs_scr_df['Full / Part Time'][ind] # add Full / Part Time data as value as value associated with job key\n",
    "    \n",
    "    # initializing columns in google_jobs_descr_df\n",
    "    google_jobs_descr_df['Key'] = ''\n",
    "    google_jobs_descr_df.insert(4, 'Source', '')\n",
    "    google_jobs_descr_df.insert(5, 'Full / Part Time', '')\n",
    "    \n",
    "    for ind in google_jobs_descr_df.index:\n",
    "        \n",
    "        df_key = google_jobs_descr_df['Role'][ind] + google_jobs_descr_df['Company'][ind] # create unique job key to be matched with key in source_dict/time_dict\n",
    "        google_jobs_descr_df['Key'][ind] = df_key\n",
    "        \n",
    "    for ind in google_jobs_descr_df.index:\n",
    "    \n",
    "        for col_key in source_dict.keys(): # matching keys between df and dicts\n",
    "\n",
    "            if google_jobs_descr_df['Key'][ind] == col_key: \n",
    "\n",
    "                # adding values associated with key\n",
    "                google_jobs_descr_df['Source'][ind] = source_dict[col_key] \n",
    "                google_jobs_descr_df['Full / Part Time'][ind] = time_dict[col_key]\n",
    "            \n",
    "    google_jobs_df = google_jobs_descr_df.drop(columns=['Key'])\n",
    "    \n",
    "    google_jobs_df = clean_sources(google_jobs_df) # cleaning up the entries in 'Source' and 'All Sources Listed'\n",
    "    \n",
    "    col = google_jobs_df.pop('All Sources Listed') # moving All Sources Listed next to Source column\n",
    "    google_jobs_df.insert(5, col.name, col)\n",
    "    \n",
    "    return google_jobs_df # updated df with new columns added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1616,
   "id": "83caeb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that cleans salary lists that would otherwise be labeled as ambiguous due to having over two entries\n",
    "# specifically, removes duplicates from lists so that they won't be flagged as having over 2 entries\n",
    "# called in pull_and_process_salaries()\n",
    "\n",
    "def clean_salary_ambiguous(row):\n",
    "    \n",
    "# row: value in the 'Salary From Text' column at a given index of the df -> will be fed in as df['Salary From Text'][ind] (str)\n",
    "    \n",
    "    #k_list = [i for i in list(range(len(lst))) if 'k' in lst[i].lower()]\n",
    "    \n",
    "    # since letters are about to be removed below, need to note when a number is really meant to be multiplied by 1000\n",
    "    if 'k' in ''.join(row).lower():\n",
    "        magnitude = 'k'\n",
    "    else:\n",
    "        magnitude = ''\n",
    "        \n",
    "    ambig_lst = []\n",
    "        \n",
    "    for i in row:\n",
    "        \n",
    "        num = re.sub(r'[^0-9.]', '', i)\n",
    "        \n",
    "        splited = num.split('.') # in case there's more than one period remaining (eg '$16.00/hr.' -> '16.00.')\n",
    "        num=\".\".join(splited[0:2])\n",
    "        num+=\"\".join(splited[2:])\n",
    "            \n",
    "        ambig_lst.append(num)\n",
    "        \n",
    "        if '' in ambig_lst: ambig_lst.remove('') # remove '' and add numbers to list as floats\n",
    "        ambig_lst = [round(float(x),1) for x in ambig_lst]    \n",
    "\n",
    "        lst_drop_dups = []\n",
    "\n",
    "        [lst_drop_dups.append(x) for x in ambig_lst if (x not in lst_drop_dups) and (x != 0)] # removing duplicates and 0s\n",
    "        \n",
    "        row = [(str(x) + magnitude) for x in lst_drop_dups] # need to convert back to str in order for the find_salaries() to properly process\n",
    "            \n",
    "    return row\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1617,
   "id": "4f5d78fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that pulls potential salaries from specified column containing job description text at specified index\n",
    "# ouputs list of potential salaries\n",
    "# called by pull_and_process_salaries()\n",
    "\n",
    "def find_salaries(df, col_name, ind):\n",
    "    \n",
    "# df: df containing all of the compiled google jobs data (DataFrame)\n",
    "# col_name: name of column containing job description text (str)\n",
    "# ind: index of df[col_name] that is being searched for salaries (int)\n",
    "    \n",
    "    salary_list = [] # initializing empty list for this job entry\n",
    "\n",
    "    phrase = df[col_name][ind] # text in description\n",
    "    phrase = phrase.replace('•',' ') # eliminating bullet points\n",
    "    phrase_to_list = phrase.split(\" \") # creating list of all strings in the description\n",
    "\n",
    "    for i in range(len(phrase_to_list)): # iterating through phrase_to_list\n",
    "\n",
    "        if len(phrase_to_list[i]) > 0: # otherwise -1 index will break code\n",
    "\n",
    "            if phrase_to_list[i] not in ['401K', '401k']: # eliminating '401K' so doesn't get labeled as salary\n",
    "\n",
    "                #CONSIDER REMOVING THIS... might do more harm than good\n",
    "                if not [True if e in phrase_to_list[i].lower() else False for e in ['b','m']][0]: # weeding out cases like '$10b industry' or '$3M company'\n",
    "                    \n",
    "                    # if there's a space between $ and number, excluding cases where '$' is last item in list (otherwise code breaks)\n",
    "                    \n",
    "                    if (i < len(phrase_to_list)-1) and (phrase_to_list[i] == '$') and (phrase_to_list[i+1][0].isdigit()): \n",
    "\n",
    "                        salary_list.append(phrase_to_list[i+1]) # add the subsequent list item in this case\n",
    "                    \n",
    "                    # looking for salary indicators (using '$' and 'K' -> in strings where '$' appears or in strings where 'K' is the last character and is directly preceded by a number\n",
    "                    \n",
    "                    elif ('$' in phrase_to_list[i]) or ((len(phrase_to_list[i]) > 1) and ('k' == phrase_to_list[i][-1].lower()) and (phrase_to_list[i][-2].isdigit())): \n",
    "                        \n",
    "                        salary_list.append(phrase_to_list[i]) # adding strings with salary indicators to ongoing list\n",
    "                        \n",
    "    return salary_list   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1618,
   "id": "96095b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that pulls salaries from the job description text using find_salaries()\n",
    "# then determines lower and upper bounds (if they exist) using data from either Scraped Salary or Salary From Text, placing them in their own columns \n",
    "# if no salaries found, or salaries cannot be determined from the collected data, will flag with text indicators\n",
    "\n",
    "def pull_and_process_salaries(df): \n",
    "\n",
    "# df: df containing all of the compiled google jobs data (DataFrame)\n",
    "    \n",
    "    df['Salary From Text'] = '' # creating column where salaries found in description will be placed\n",
    "    df['Salary Lower Bound'] = '' # lower bound\n",
    "    df['Salary Upper Bound'] = '' # upper bound\n",
    "    \n",
    "    # pulling salaries from the different text boxes\n",
    "    \n",
    "    for ind in df.index: # first round iterating through df\n",
    "        \n",
    "        if df['Any Other Text'][ind] is not np.nan: # if Any Other Text is not empty, it means that no text was found in either Job Highlights or Job Description\n",
    "            \n",
    "             df['Salary From Text'][ind] = find_salaries(df, 'Any Other Text', ind) # in these cases, look for salaries in Any Other Text\n",
    "            \n",
    "        else: # otherwise pull salaries from Job Highlights\n",
    "            \n",
    "            df['Salary From Text'][ind] = find_salaries(df, 'Job Highlights', ind)\n",
    "        \n",
    "            if df['Salary From Text'][ind] == []: # if salary was not found in Job Highlights, look for salary in Job Description\n",
    "                \n",
    "                df['Salary From Text'][ind] = find_salaries(df, 'Job Description', ind)\n",
    "\n",
    "    # now that salaries are pulled from the description text, will create lower and upper bounds based on given info\n",
    "    \n",
    "    for ind in df.index:\n",
    "    \n",
    "        if df['Scraped Salary'][ind] == '*missing data*': # if salary not initially scraped\n",
    "\n",
    "            if df['Salary From Text'][ind] == []: # if no salary found in any of the description texts\n",
    "\n",
    "                df['Salary Lower Bound'][ind] = '*no salary found*'\n",
    "                df['Salary Upper Bound'][ind] = '*no salary found*'\n",
    "\n",
    "            else: # if salary is found anywhere on the description page\n",
    "\n",
    "                # if first value is just $, remove it so doesn't affect making the range (cases where there's originally a space between $ and number -> '$ 10/hr' becomes ['$','10'])\n",
    "\n",
    "#                 for i in df['Salary From Text'][ind]:\n",
    "#                     if i == '$':\n",
    "#                         df['Salary From Text'][ind].remove('$') \n",
    "\n",
    "                desc_sal_list = [] # in cases where there are two \"numbers\" that are really 1-2 ranges -> [20K-30K,5K-6K] or [20K,15K-16K]\n",
    "\n",
    "                for i in range(len(df['Salary From Text'][ind])): # removing the dashes and isolating all of the individual numbers\n",
    "\n",
    "                    if '–' in df['Salary From Text'][ind][i]: \n",
    "                        desc_sal = df['Salary From Text'][ind][i].replace('–', ' ')\n",
    "                    if '—' in df['Salary From Text'][ind][i]: \n",
    "                        desc_sal = df['Salary From Text'][ind][i].replace('—', ' ')\n",
    "                    elif '-' in df['Salary From Text'][ind][i]:\n",
    "                        desc_sal = df['Salary From Text'][ind][i].replace('-', ' ')\n",
    "                    else:\n",
    "                        desc_sal = df['Salary From Text'][ind][i]\n",
    "\n",
    "                    desc_sal_list = desc_sal_list + desc_sal.split(' ')\n",
    "\n",
    "                    if '' in desc_sal_list: desc_sal_list.remove('')\n",
    "\n",
    "                df['Salary From Text'][ind] = desc_sal_list\n",
    "\n",
    "                # attempting to preemptively correct cases that would otherwise trigger 'salary ambiguous' label so that they can be properly processed\n",
    "\n",
    "                if len(df['Salary From Text'][ind]) > 2: # when length of list > 2, will be marked ambiguous unless corrected first\n",
    "\n",
    "                    df['Salary From Text'][ind] = clean_salary_ambiguous(df['Salary From Text'][ind]) # using clean_salary_ambiguous() function\n",
    "\n",
    "                # now that all the lists are as cleaned up as possible, proceed to determine salary ranges:\n",
    "\n",
    "                if len(df['Salary From Text'][ind]) > 2: # if multiple numbers are still found after cleaning, hard to tell what salary range is, will be marked ambiguous\n",
    "\n",
    "                    df['Salary Lower Bound'][ind] = '*salary ambiguous*'\n",
    "                    df['Salary Upper Bound'][ind] = '*salary ambiguous*'\n",
    "\n",
    "                if len(df['Salary From Text'][ind]) == 2: # if two entries provided, create salary range\n",
    "\n",
    "                    df['Salary Lower Bound'][ind] = df['Salary From Text'][ind][0] \n",
    "                    df['Salary Upper Bound'][ind] = df['Salary From Text'][ind][1]\n",
    "\n",
    "                elif len(df['Salary From Text'][ind]) == 1: # one entry\n",
    "\n",
    "                    df['Salary Lower Bound'][ind] = df['Salary From Text'][ind][0] \n",
    "\n",
    "        else: # if salary found in initial scrape, use it as final salary  \n",
    "\n",
    "            if '–' in df['Scraped Salary'][ind]: # removing dashes\n",
    "                scraped_sal = df['Scraped Salary'][ind].replace('–', ' ')\n",
    "            elif '—' in df['Scraped Salary'][ind]: # removing dashes\n",
    "                scraped_sal = df['Scraped Salary'][ind].replace('—', ' ')\n",
    "            elif '-' in df['Scraped Salary'][ind]: # removing dashes\n",
    "                scraped_sal = df['Scraped Salary'][ind].replace('-', ' ')\n",
    "            else: # if no dashes present, just leave as is\n",
    "                scraped_sal = df['Scraped Salary'][ind]\n",
    "\n",
    "            scraped_sal_list = scraped_sal.split(' ') # seperating into list of strings\n",
    "\n",
    "            df['Salary Lower Bound'][ind] = scraped_sal_list[0] # first number\n",
    "            df['Salary Upper Bound'][ind] = scraped_sal_list[1] # second number\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1619,
   "id": "afb6402e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that cleans salaries pulled from text in string form, then converts them to numbers\n",
    "# creates salary ranges and ratios\n",
    "# flags when no salary range or ratio can be generated due to insufficient/ nonexistent data\n",
    "\n",
    "def clean_salaries(df):\n",
    "    \n",
    "# df: df containing all of the processed google jobs data (DataFrame)\n",
    "    \n",
    "#     df['Salary Magnitude Lower'] = '' \n",
    "#     df['Salary Magnitude Upper'] = '' \n",
    "    df['Salary Magnitude'] = ''\n",
    "    df['Salary Range'] = ''\n",
    "    df['Salary Ratio'] = ''\n",
    "    \n",
    "    for ind in df.index:\n",
    "        \n",
    "        lower = df['Salary Lower Bound'][ind]\n",
    "        upper = df['Salary Upper Bound'][ind]\n",
    "        \n",
    "        if df['Salary Lower Bound'][ind] not in ['*no salary found*','*salary ambiguous*']: # only for entries that have values\n",
    "            \n",
    "            # before removing letters, saving info on whether any final numbers should be multipled by 1000 (indicated by 'K' after the number)\n",
    "            \n",
    "            k_index_lower = lower.lower().find('k') # finding index of 'k'\n",
    "            k_index_upper = upper.lower().find('k')\n",
    "                \n",
    "            # if k present in string (and is preceded by a number rather than a letter, to avoid including things like '$10/week'), note that final number should be multiplied by 1000\n",
    "            #df['Salary Magnitude Lower'][ind] = [1000 if (k_index_lower != -1) and (lower.lower()[k_index_lower - 1].isdigit()) else 1][0]\n",
    "            df['Salary Magnitude'][ind] = [1000 if ((k_index_lower != -1) and (lower.lower()[k_index_lower - 1].isdigit())) or ((k_index_upper != -1) and (upper.lower()[k_index_upper - 1].isdigit())) else 1][0]\n",
    "            \n",
    "            # removing all non-numerical characters except for decimals\n",
    "\n",
    "            lower = re.sub(r'[^0-9.]', '', lower)\n",
    "            \n",
    "            splited = lower.split('.') # in case there's more than one period remaining (eg '$16.00/hr.' -> '16.00.')\n",
    "            lower=\".\".join(splited[0:2])\n",
    "            lower+=\"\".join(splited[2:])\n",
    "            \n",
    "            df['Salary Lower Bound'][ind] = lower # cleaned upper bound\n",
    "             \n",
    "            upper = re.sub(r'[^0-9.]', '', upper)\n",
    "            \n",
    "            splited = upper.split('.')\n",
    "            upper=\".\".join(splited[0:2])\n",
    "            upper+=\"\".join(splited[2:])\n",
    "        \n",
    "            df['Salary Upper Bound'][ind] = upper # cleaned upper bound\n",
    "    \n",
    "            # if this cleaning leaves the entry emtpy, leave this message:\n",
    "            \n",
    "            df['Salary Lower Bound'][ind] = ['*no number present*' if df['Salary Lower Bound'][ind] == '' else df['Salary Lower Bound'][ind]][0] \n",
    "            df['Salary Upper Bound'][ind] = ['*no number present*' if df['Salary Upper Bound'][ind] == '' else df['Salary Upper Bound'][ind]][0] \n",
    "           \n",
    "            # multiplying by 1 or 1000 depending on whether or not 'K' was present in original entry\n",
    "            \n",
    "            if df['Salary Lower Bound'][ind] != '*no number present*': # if number found\n",
    "\n",
    "                df['Salary Lower Bound'][ind] = (float(df['Salary Lower Bound'][ind]) * df['Salary Magnitude'][ind])\n",
    "            \n",
    "            if df['Salary Upper Bound'][ind] != '*no number present*':\n",
    "    \n",
    "                df['Salary Upper Bound'][ind] = float(df['Salary Upper Bound'][ind]) * df['Salary Magnitude'][ind]\n",
    "                \n",
    "            # checking for cases where lower bound is 0 (likely not refering to a salary, so should be removed)\n",
    " \n",
    "            if df['Salary Lower Bound'][ind] == 0:\n",
    "\n",
    "                # cases where lower and upper bound both exist\n",
    "\n",
    "                if (df['Salary Lower Bound'][ind] != '*no number present*') and (df['Salary Upper Bound'][ind] != '*no number present*'):\n",
    "\n",
    "                    df['Salary Lower Bound'][ind] = df['Salary Upper Bound'][ind] # make the upper bound the lower bound\n",
    "                    df['Salary Upper Bound'][ind] = '*no number present*' # remove upper bound\n",
    "\n",
    "                # cases where just lower bound exists\n",
    "\n",
    "                elif (df['Salary Lower Bound'][ind] != '*no number present*') and (df['Salary Upper Bound'][ind] == '*no number present*'):\n",
    "\n",
    "                    df['Salary Lower Bound'][ind] = '*no number present*' # remove lower bound\n",
    "            \n",
    "            # if there are two numbers (lower and upper bounds), create column with polished range, add ratio to new col\n",
    "            \n",
    "            if (df['Salary Lower Bound'][ind] != '*no number present*') and (df['Salary Upper Bound'][ind] != '*no number present*'):\n",
    "                        \n",
    "                # in cases where they were placed in wrong order\n",
    "\n",
    "                if df['Salary Lower Bound'][ind] > df['Salary Upper Bound'][ind]: \n",
    "            \n",
    "                    real_upper = df['Salary Lower Bound'][ind] \n",
    "                    real_lower = df['Salary Upper Bound'][ind]\n",
    "\n",
    "                    df['Salary Lower Bound'][ind] = real_lower # switching which column each is placed in\n",
    "                    df['Salary Upper Bound'][ind] = real_upper\n",
    "                \n",
    "                df['Salary Range'][ind] = '${:,.2f}'.format(df['Salary Lower Bound'][ind]) + '-' + '${:,.2f}'.format(df['Salary Upper Bound'][ind])\n",
    "                df['Salary Ratio'][ind] = round((df['Salary Upper Bound'][ind] / df['Salary Lower Bound'][ind]),1) \n",
    "                \n",
    "            # if just one value, include that value alone, with ratio set to 1\n",
    "            \n",
    "            elif (df['Salary Lower Bound'][ind] != '*no number present*') and (df['Salary Upper Bound'][ind] == '*no number present*'):\n",
    "                \n",
    "                df['Salary Range'][ind] = '${:,.2f}'.format(df['Salary Lower Bound'][ind])\n",
    "                df['Salary Ratio'][ind] = 1.0\n",
    "             \n",
    "            # if just one value found, but for whatever reason placed in upper bound, move to lower bound, and then set ratio to 1\n",
    "            \n",
    "            elif (df['Salary Lower Bound'][ind] == '*no number present*') and (df['Salary Upper Bound'][ind] != '*no number present*'):\n",
    "\n",
    "                df['Salary Lower Bound'][ind] = df['Salary Upper Bound'][ind]\n",
    "                df['Salary Upper Bound'][ind] = '*no number present*'\n",
    "                \n",
    "                df['Salary Range'][ind] = '${:,.2f}'.format(df['Salary Lower Bound'][ind])\n",
    "                df['Salary Ratio'][ind] = 1.0\n",
    "                \n",
    "            # if both numbers were removed in cleaning process, treat as if no salary was found\n",
    "            \n",
    "            elif (df['Salary Lower Bound'][ind] == '*no number present*') and (df['Salary Upper Bound'][ind] == '*no number present*'):\n",
    "                \n",
    "                df['Salary Range'][ind] = '*no salary found*'\n",
    "                df['Salary Ratio'][ind] = '*no salary found*'\n",
    "            \n",
    "        if df['Salary Lower Bound'][ind] == '*no salary found*': # if no salary found\n",
    "            \n",
    "            df['Salary Range'][ind] = '*no salary found*'\n",
    "            df['Salary Ratio'][ind] = '*no salary found*'\n",
    "                \n",
    "        if df['Salary Lower Bound'][ind] == '*salary ambiguous*': # if salary cannot be determined\n",
    "\n",
    "            df['Salary Range'][ind] = '*salary ambiguous*'\n",
    "            df['Salary Ratio'][ind] = '*salary ambiguous*'\n",
    "                \n",
    "    df = df.drop(columns=['Salary Magnitude'])\n",
    "                   \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1620,
   "id": "664fb9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that allows for manual updating of salary lower bound, upper bound, range, and ratio at specific index\n",
    "\n",
    "def update_salary(df, lower, upper, ind, note):\n",
    "    \n",
    "# df: df containing all of the cleaned google jobs data (DataFrame)\n",
    "# lower: updated salary lower bound (int)\n",
    "# upper: updated salary upper bound (int)\n",
    "# ind: index where updated salary information will be placed (int\n",
    "    \n",
    "    # manually entering lower and upper bounds, updating salary range and ratio\n",
    "    \n",
    "    if (not lower) and (not upper):\n",
    "        \n",
    "        df['Salary Lower Bound'][ind] = '*no salary found*'\n",
    "        df['Salary Upper Bound'][ind] = '*no salary found*'\n",
    "        df['Salary Range'][ind] = '*no salary found*'\n",
    "        df['Salary Ratio'][ind] = '*no salary found*'\n",
    "    \n",
    "    elif (lower) and (not upper):\n",
    "    \n",
    "        df['Salary Lower Bound'][ind] = lower\n",
    "        df['Salary Upper Bound'][ind] = '*no number present*'\n",
    "        df['Salary Range'][ind] = '${:,.2f}'.format(df['Salary Lower Bound'][ind])\n",
    "        df['Salary Ratio'][ind] = 1 \n",
    "        \n",
    "        \n",
    "    elif (lower) and (upper):\n",
    "    \n",
    "        df['Salary Lower Bound'][ind] = lower\n",
    "        df['Salary Upper Bound'][ind] = upper\n",
    "        df['Salary Range'][ind] = '${:,.2f}'.format(df['Salary Lower Bound'][ind]) + '-' + '${:,.2f}'.format(df['Salary Upper Bound'][ind])\n",
    "        df['Salary Ratio'][ind] = round((df['Salary Upper Bound'][ind] / df['Salary Lower Bound'][ind]),1) \n",
    "        \n",
    "    df['Notes'][ind] = note    \n",
    "    \n",
    "    return\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a4af44",
   "metadata": {},
   "source": [
    "## Taking a Look at the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1936,
   "id": "e3a38d99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # results from local function\n",
    "\n",
    "# google_jobs_scr_df = pd.read_csv(scroll_df_path)\n",
    "# google_jobs_descr_df = pd.read_csv(descr_df_path)\n",
    "# google_jobs_df = add_columns(google_jobs_descr_df, google_jobs_scr_df) # adding 'Source' and 'Full / Part Time'\n",
    "#     #google_jobs_df_add_sal = find_salaries(google_jobs_df)\n",
    "# google_jobs_df_add_sal = pull_and_process_salaries(google_jobs_df)\n",
    "# google_jobs_df_cleaned = clean_salaries(google_jobs_df_add_sal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1864,
   "id": "794386b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# results from cron job scrape\n",
    "\n",
    "google_jobs_descr_test = pd.read_csv('/Users/ravram/Desktop/google-jobs-cronjob.csv')\n",
    "google_jobs_scr_test = pd.read_csv('/Users/ravram/Desktop/google-jobs-extra-cols-cronjob.csv')\n",
    "google_jobs_test = add_columns(google_jobs_descr_test, google_jobs_scr_test) \n",
    "    #google_jobs_df_add_sal_test = find_salaries(google_jobs_test)\n",
    "google_jobs_df_add_sal_test = pull_and_process_salaries(google_jobs_test)\n",
    "google_jobs_df_cleaned_test = clean_salaries(google_jobs_df_add_sal_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1865,
   "id": "705fabf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0x/wbh6lcrn3t7046vw2zxtbrhxrc0v0g/T/ipykernel_20573/3442634355.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Date Scraped'][ind] = pd.to_datetime(new_date)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Role</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date Scraped</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-09-15</th>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-16</th>\n",
       "      <td>508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-17</th>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-18</th>\n",
       "      <td>472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-19</th>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-20</th>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-21</th>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-22</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-23</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-24</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-25</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-26</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-27</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-28</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-29</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-03</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-04</th>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-05</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Role\n",
       "Date Scraped      \n",
       "2023-09-15     250\n",
       "2023-09-16     508\n",
       "2023-09-17     513\n",
       "2023-09-18     472\n",
       "2023-09-19     506\n",
       "2023-09-20     522\n",
       "2023-09-21     178\n",
       "2023-09-22      10\n",
       "2023-09-23       2\n",
       "2023-09-24      14\n",
       "2023-09-25      25\n",
       "2023-09-26      25\n",
       "2023-09-27      36\n",
       "2023-09-28      42\n",
       "2023-09-29      29\n",
       "2023-10-03      25\n",
       "2023-10-04      75\n",
       "2023-10-05      41"
      ]
     },
     "execution_count": 1865,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# taking a look at the number of postings added each day\n",
    "\n",
    "test = deepcopy(google_jobs_test)\n",
    "test['Date Scraped'] = pd.to_datetime(test['Date Scraped'])\n",
    "\n",
    "def drop_minutes(df):\n",
    "    \n",
    "    for ind in df.index:\n",
    "        \n",
    "        old_date = df['Date Scraped'][ind]\n",
    "        \n",
    "        new_date = old_date.replace(minute=0, second=0, microsecond=0)# + datetime.timedelta(hours=1)\n",
    "        \n",
    "        df['Date Scraped'][ind] = pd.to_datetime(new_date)\n",
    "    \n",
    "    return \n",
    "\n",
    "drop_minutes(test)\n",
    "\n",
    "test.groupby(test['Date Scraped'].dt.date).count()[['Role']]#.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1866,
   "id": "619c92aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Role': {Timestamp('2023-09-15 15:00:00'): 7,\n",
       "  Timestamp('2023-09-15 16:00:00'): 27,\n",
       "  Timestamp('2023-09-15 17:00:00'): 13,\n",
       "  Timestamp('2023-09-15 19:00:00'): 26,\n",
       "  Timestamp('2023-09-15 20:00:00'): 123,\n",
       "  Timestamp('2023-09-15 23:00:00'): 54,\n",
       "  Timestamp('2023-09-16 01:00:00'): 34,\n",
       "  Timestamp('2023-09-16 02:00:00'): 11,\n",
       "  Timestamp('2023-09-16 03:00:00'): 23,\n",
       "  Timestamp('2023-09-16 04:00:00'): 17,\n",
       "  Timestamp('2023-09-16 06:00:00'): 53,\n",
       "  Timestamp('2023-09-16 07:00:00'): 26,\n",
       "  Timestamp('2023-09-16 09:00:00'): 40,\n",
       "  Timestamp('2023-09-16 10:00:00'): 37,\n",
       "  Timestamp('2023-09-16 11:00:00'): 22,\n",
       "  Timestamp('2023-09-16 12:00:00'): 15,\n",
       "  Timestamp('2023-09-16 13:00:00'): 29,\n",
       "  Timestamp('2023-09-16 14:00:00'): 17,\n",
       "  Timestamp('2023-09-16 16:00:00'): 28,\n",
       "  Timestamp('2023-09-16 17:00:00'): 13,\n",
       "  Timestamp('2023-09-16 18:00:00'): 15,\n",
       "  Timestamp('2023-09-16 20:00:00'): 95,\n",
       "  Timestamp('2023-09-16 21:00:00'): 33,\n",
       "  Timestamp('2023-09-17 01:00:00'): 71,\n",
       "  Timestamp('2023-09-17 02:00:00'): 21,\n",
       "  Timestamp('2023-09-17 03:00:00'): 40,\n",
       "  Timestamp('2023-09-17 04:00:00'): 34,\n",
       "  Timestamp('2023-09-17 05:00:00'): 24,\n",
       "  Timestamp('2023-09-17 08:00:00'): 55,\n",
       "  Timestamp('2023-09-17 10:00:00'): 33,\n",
       "  Timestamp('2023-09-17 12:00:00'): 51,\n",
       "  Timestamp('2023-09-17 14:00:00'): 23,\n",
       "  Timestamp('2023-09-17 15:00:00'): 18,\n",
       "  Timestamp('2023-09-17 16:00:00'): 12,\n",
       "  Timestamp('2023-09-17 18:00:00'): 23,\n",
       "  Timestamp('2023-09-17 19:00:00'): 16,\n",
       "  Timestamp('2023-09-17 23:00:00'): 92,\n",
       "  Timestamp('2023-09-18 02:00:00'): 47,\n",
       "  Timestamp('2023-09-18 03:00:00'): 44,\n",
       "  Timestamp('2023-09-18 07:00:00'): 65,\n",
       "  Timestamp('2023-09-18 08:00:00'): 8,\n",
       "  Timestamp('2023-09-18 10:00:00'): 35,\n",
       "  Timestamp('2023-09-18 11:00:00'): 30,\n",
       "  Timestamp('2023-09-18 12:00:00'): 13,\n",
       "  Timestamp('2023-09-18 13:00:00'): 10,\n",
       "  Timestamp('2023-09-18 14:00:00'): 19,\n",
       "  Timestamp('2023-09-18 17:00:00'): 34,\n",
       "  Timestamp('2023-09-18 18:00:00'): 12,\n",
       "  Timestamp('2023-09-18 21:00:00'): 113,\n",
       "  Timestamp('2023-09-18 22:00:00'): 14,\n",
       "  Timestamp('2023-09-18 23:00:00'): 28,\n",
       "  Timestamp('2023-09-19 01:00:00'): 35,\n",
       "  Timestamp('2023-09-19 02:00:00'): 8,\n",
       "  Timestamp('2023-09-19 05:00:00'): 32,\n",
       "  Timestamp('2023-09-19 06:00:00'): 45,\n",
       "  Timestamp('2023-09-19 07:00:00'): 31,\n",
       "  Timestamp('2023-09-19 08:00:00'): 26,\n",
       "  Timestamp('2023-09-19 09:00:00'): 29,\n",
       "  Timestamp('2023-09-19 10:00:00'): 28,\n",
       "  Timestamp('2023-09-19 11:00:00'): 21,\n",
       "  Timestamp('2023-09-19 12:00:00'): 30,\n",
       "  Timestamp('2023-09-19 13:00:00'): 16,\n",
       "  Timestamp('2023-09-19 16:00:00'): 38,\n",
       "  Timestamp('2023-09-19 17:00:00'): 12,\n",
       "  Timestamp('2023-09-19 19:00:00'): 19,\n",
       "  Timestamp('2023-09-19 21:00:00'): 98,\n",
       "  Timestamp('2023-09-19 23:00:00'): 38,\n",
       "  Timestamp('2023-09-20 00:00:00'): 12,\n",
       "  Timestamp('2023-09-20 01:00:00'): 11,\n",
       "  Timestamp('2023-09-20 02:00:00'): 16,\n",
       "  Timestamp('2023-09-20 03:00:00'): 25,\n",
       "  Timestamp('2023-09-20 04:00:00'): 15,\n",
       "  Timestamp('2023-09-20 05:00:00'): 13,\n",
       "  Timestamp('2023-09-20 06:00:00'): 28,\n",
       "  Timestamp('2023-09-20 07:00:00'): 49,\n",
       "  Timestamp('2023-09-20 08:00:00'): 18,\n",
       "  Timestamp('2023-09-20 11:00:00'): 36,\n",
       "  Timestamp('2023-09-20 12:00:00'): 25,\n",
       "  Timestamp('2023-09-20 14:00:00'): 35,\n",
       "  Timestamp('2023-09-20 15:00:00'): 25,\n",
       "  Timestamp('2023-09-20 16:00:00'): 20,\n",
       "  Timestamp('2023-09-20 18:00:00'): 28,\n",
       "  Timestamp('2023-09-20 19:00:00'): 4,\n",
       "  Timestamp('2023-09-20 20:00:00'): 106,\n",
       "  Timestamp('2023-09-20 21:00:00'): 19,\n",
       "  Timestamp('2023-09-20 22:00:00'): 22,\n",
       "  Timestamp('2023-09-20 23:00:00'): 15,\n",
       "  Timestamp('2023-09-21 03:00:00'): 46,\n",
       "  Timestamp('2023-09-21 04:00:00'): 28,\n",
       "  Timestamp('2023-09-21 05:00:00'): 13,\n",
       "  Timestamp('2023-09-21 06:00:00'): 38,\n",
       "  Timestamp('2023-09-21 07:00:00'): 26,\n",
       "  Timestamp('2023-09-21 08:00:00'): 5,\n",
       "  Timestamp('2023-09-21 11:00:00'): 3,\n",
       "  Timestamp('2023-09-21 12:00:00'): 3,\n",
       "  Timestamp('2023-09-21 13:00:00'): 2,\n",
       "  Timestamp('2023-09-21 14:00:00'): 3,\n",
       "  Timestamp('2023-09-21 15:00:00'): 3,\n",
       "  Timestamp('2023-09-21 17:00:00'): 3,\n",
       "  Timestamp('2023-09-21 21:00:00'): 2,\n",
       "  Timestamp('2023-09-21 22:00:00'): 1,\n",
       "  Timestamp('2023-09-21 23:00:00'): 2,\n",
       "  Timestamp('2023-09-22 03:00:00'): 1,\n",
       "  Timestamp('2023-09-22 04:00:00'): 1,\n",
       "  Timestamp('2023-09-22 05:00:00'): 2,\n",
       "  Timestamp('2023-09-22 08:00:00'): 1,\n",
       "  Timestamp('2023-09-22 09:00:00'): 1,\n",
       "  Timestamp('2023-09-22 10:00:00'): 2,\n",
       "  Timestamp('2023-09-22 17:00:00'): 1,\n",
       "  Timestamp('2023-09-22 21:00:00'): 1,\n",
       "  Timestamp('2023-09-23 00:00:00'): 1,\n",
       "  Timestamp('2023-09-23 18:00:00'): 1,\n",
       "  Timestamp('2023-09-24 00:00:00'): 1,\n",
       "  Timestamp('2023-09-24 03:00:00'): 2,\n",
       "  Timestamp('2023-09-24 04:00:00'): 1,\n",
       "  Timestamp('2023-09-24 09:00:00'): 2,\n",
       "  Timestamp('2023-09-24 11:00:00'): 1,\n",
       "  Timestamp('2023-09-24 12:00:00'): 2,\n",
       "  Timestamp('2023-09-24 14:00:00'): 1,\n",
       "  Timestamp('2023-09-24 22:00:00'): 3,\n",
       "  Timestamp('2023-09-24 23:00:00'): 1,\n",
       "  Timestamp('2023-09-25 00:00:00'): 1,\n",
       "  Timestamp('2023-09-25 01:00:00'): 1,\n",
       "  Timestamp('2023-09-25 03:00:00'): 4,\n",
       "  Timestamp('2023-09-25 06:00:00'): 1,\n",
       "  Timestamp('2023-09-25 07:00:00'): 1,\n",
       "  Timestamp('2023-09-25 10:00:00'): 1,\n",
       "  Timestamp('2023-09-25 11:00:00'): 1,\n",
       "  Timestamp('2023-09-25 12:00:00'): 3,\n",
       "  Timestamp('2023-09-25 14:00:00'): 1,\n",
       "  Timestamp('2023-09-25 15:00:00'): 4,\n",
       "  Timestamp('2023-09-25 16:00:00'): 1,\n",
       "  Timestamp('2023-09-25 18:00:00'): 1,\n",
       "  Timestamp('2023-09-25 19:00:00'): 1,\n",
       "  Timestamp('2023-09-25 20:00:00'): 1,\n",
       "  Timestamp('2023-09-25 21:00:00'): 1,\n",
       "  Timestamp('2023-09-25 22:00:00'): 2,\n",
       "  Timestamp('2023-09-26 00:00:00'): 5,\n",
       "  Timestamp('2023-09-26 03:00:00'): 2,\n",
       "  Timestamp('2023-09-26 05:00:00'): 2,\n",
       "  Timestamp('2023-09-26 08:00:00'): 1,\n",
       "  Timestamp('2023-09-26 09:00:00'): 1,\n",
       "  Timestamp('2023-09-26 10:00:00'): 2,\n",
       "  Timestamp('2023-09-26 12:00:00'): 1,\n",
       "  Timestamp('2023-09-26 14:00:00'): 1,\n",
       "  Timestamp('2023-09-26 16:00:00'): 1,\n",
       "  Timestamp('2023-09-26 17:00:00'): 2,\n",
       "  Timestamp('2023-09-26 18:00:00'): 3,\n",
       "  Timestamp('2023-09-26 19:00:00'): 2,\n",
       "  Timestamp('2023-09-26 20:00:00'): 1,\n",
       "  Timestamp('2023-09-26 21:00:00'): 1,\n",
       "  Timestamp('2023-09-27 01:00:00'): 2,\n",
       "  Timestamp('2023-09-27 03:00:00'): 2,\n",
       "  Timestamp('2023-09-27 04:00:00'): 1,\n",
       "  Timestamp('2023-09-27 05:00:00'): 2,\n",
       "  Timestamp('2023-09-27 06:00:00'): 1,\n",
       "  Timestamp('2023-09-27 08:00:00'): 2,\n",
       "  Timestamp('2023-09-27 10:00:00'): 2,\n",
       "  Timestamp('2023-09-27 11:00:00'): 1,\n",
       "  Timestamp('2023-09-27 14:00:00'): 1,\n",
       "  Timestamp('2023-09-27 15:00:00'): 9,\n",
       "  Timestamp('2023-09-27 16:00:00'): 6,\n",
       "  Timestamp('2023-09-27 20:00:00'): 7,\n",
       "  Timestamp('2023-09-28 00:00:00'): 11,\n",
       "  Timestamp('2023-09-28 20:00:00'): 31,\n",
       "  Timestamp('2023-09-29 00:00:00'): 16,\n",
       "  Timestamp('2023-09-29 08:00:00'): 13,\n",
       "  Timestamp('2023-10-03 12:00:00'): 6,\n",
       "  Timestamp('2023-10-03 16:00:00'): 7,\n",
       "  Timestamp('2023-10-03 20:00:00'): 12,\n",
       "  Timestamp('2023-10-04 00:00:00'): 10,\n",
       "  Timestamp('2023-10-04 04:00:00'): 10,\n",
       "  Timestamp('2023-10-04 08:00:00'): 22,\n",
       "  Timestamp('2023-10-04 12:00:00'): 7,\n",
       "  Timestamp('2023-10-04 16:00:00'): 13,\n",
       "  Timestamp('2023-10-04 20:00:00'): 13,\n",
       "  Timestamp('2023-10-05 00:00:00'): 16,\n",
       "  Timestamp('2023-10-05 04:00:00'): 14,\n",
       "  Timestamp('2023-10-05 08:00:00'): 11}}"
      ]
     },
     "execution_count": 1866,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.groupby('Date Scraped').count()[['Role']].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1867,
   "id": "abf93d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries with Potential Salaries Found: 2294\n",
      "Total Entries: 4104\n",
      "As a percent: 55.9 %\n"
     ]
    }
   ],
   "source": [
    "# percent of entries with potential salary found:\n",
    "\n",
    "print('Entries with Potential Salaries Found:', len(google_jobs_df_cleaned_test[(google_jobs_df_cleaned_test['Salary Range'] != '*no salary found*')]))\n",
    "print('Total Entries:', len(google_jobs_df_cleaned_test))\n",
    "\n",
    "print('As a percent:', (round(100*len(google_jobs_df_cleaned_test[(google_jobs_df_cleaned_test['Salary Range'] != '*no salary found*')]) / len(google_jobs_df_cleaned_test),2)), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1871,
   "id": "78d774be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Role</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Posted</th>\n",
       "      <th>Source</th>\n",
       "      <th>All Sources Listed</th>\n",
       "      <th>Full / Part Time</th>\n",
       "      <th>Scraped Salary</th>\n",
       "      <th>Job Highlights</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Any Other Text</th>\n",
       "      <th>Date Scraped</th>\n",
       "      <th>Salary From Text</th>\n",
       "      <th>Salary Lower Bound</th>\n",
       "      <th>Salary Upper Bound</th>\n",
       "      <th>Salary Range</th>\n",
       "      <th>Salary Ratio</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Account Executive (Professional Information Bu...</td>\n",
       "      <td>Dow Jones</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>22 hours ago</td>\n",
       "      <td>Dow Jones Jobs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>*missing data*</td>\n",
       "      <td>Qualifications•An ability to develop and imple...</td>\n",
       "      <td>Job Description:About us:\\n\\nDow Jones is a gl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[$50,000, $180,000]</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>$50,000.00-$180,000.00</td>\n",
       "      <td>3.6</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>Security Analyst</td>\n",
       "      <td>Get It Recruit - Administrative</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>21 hours ago</td>\n",
       "      <td>Get.It</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>40K–180K a year</td>\n",
       "      <td>Qualifications•Proficient technical skills and...</td>\n",
       "      <td>Summary Description:\\n\\nWe are seeking an expe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>$40,000.00-$180,000.00</td>\n",
       "      <td>4.5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>Side Hustle/Closer</td>\n",
       "      <td>Bravado</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>17 hours ago</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-time and Part-time</td>\n",
       "      <td>*missing data*</td>\n",
       "      <td>Responsibilities•Strategizing with team member...</td>\n",
       "      <td>(Side-Gig) Side Hustle/Closer\\n\\nUnited States...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[$100, 1000]</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>$100.00-$1,000.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>Customer Service Representative (CSR)</td>\n",
       "      <td>soustar</td>\n",
       "      <td>Bronx, NY</td>\n",
       "      <td>19 hours ago</td>\n",
       "      <td>Job Today</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>*missing data*</td>\n",
       "      <td>*missing data*</td>\n",
       "      <td>*missing data*</td>\n",
       "      <td>Empresa latinoamericana busca personal para ex...</td>\n",
       "      <td>2023-09-15 20:01:33.591285</td>\n",
       "      <td>[$1,000, $3,500]</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>$1,000.00-$3,500.00</td>\n",
       "      <td>3.5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>Programming In New York City</td>\n",
       "      <td>BuffTutor Network</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>20 hours ago</td>\n",
       "      <td>BuffTutor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Part-time and Contractor</td>\n",
       "      <td>15–60 an hour</td>\n",
       "      <td>Qualifications•Have at least a 3.0 or better m...</td>\n",
       "      <td>BuffTutor is a network of experienced and pass...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-09-16 09:01:52.937797</td>\n",
       "      <td>[]</td>\n",
       "      <td>15.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>$15.00-$60.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>Director of Performance Media</td>\n",
       "      <td>Get It Recruit - Marketing</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>8 hours ago</td>\n",
       "      <td>Get.It</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>55K–172K a year</td>\n",
       "      <td>Qualifications•Strong leadership skills with e...</td>\n",
       "      <td>Director of Performance Media - Remote Opportu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-09-17 18:01:21.811309</td>\n",
       "      <td>[$1]</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>172000.0</td>\n",
       "      <td>$55,000.00-$172,000.00</td>\n",
       "      <td>3.1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>Academic Dermatologist Specialized in Pigmente...</td>\n",
       "      <td>Drug Information Association Inc</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>6 hours ago</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>150K–500K a year</td>\n",
       "      <td>Qualifications•Applicants must have pigmented ...</td>\n",
       "      <td>Internal Number: 67287\\n\\nPay Range...\\n\\n$150...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-09-18 03:01:37.580887</td>\n",
       "      <td>[$150,000-$500,000, $150K-$510K]</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>$150,000.00-$500,000.00</td>\n",
       "      <td>3.3</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>Senior Recruiter</td>\n",
       "      <td>Green Key Resources</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>10 hours ago</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>45K–250K a year</td>\n",
       "      <td>Qualifications•BA/BS Degree in Accounting, Bus...</td>\n",
       "      <td>POSITION OVERVIEW\\n\\nGreen Key Resources is cu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-09-18 21:01:59.182227</td>\n",
       "      <td>[]</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>$45,000.00-$250,000.00</td>\n",
       "      <td>5.6</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3704</th>\n",
       "      <td>Senior Leader, Product Marketing</td>\n",
       "      <td>Get It Recruit - Marketing</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>16 hours ago</td>\n",
       "      <td>Get.It</td>\n",
       "      <td>[Get.It]</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>55K–172K a year</td>\n",
       "      <td>Qualifications•Strong coordination, stakeholde...</td>\n",
       "      <td>Summary Description:\\nAlgolia is seeking a Sen...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-09-21 06:01:48.035545</td>\n",
       "      <td>[]</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>172000.0</td>\n",
       "      <td>$55,000.00-$172,000.00</td>\n",
       "      <td>3.1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3791</th>\n",
       "      <td>DSW Careers in Columbus OH &amp; Across the USA Jo...</td>\n",
       "      <td>Designer Brands</td>\n",
       "      <td>United States (+11 others)</td>\n",
       "      <td>45 minutes ago</td>\n",
       "      <td>247 Careers For Freshers</td>\n",
       "      <td>[247 Careers For Freshers]</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>27,236–239,718 a year</td>\n",
       "      <td>Qualifications•Your resume proves you in your ...</td>\n",
       "      <td>If you are interested to work in retail indust...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-09-23 18:00:18.022149</td>\n",
       "      <td>[]</td>\n",
       "      <td>27236.0</td>\n",
       "      <td>239718.0</td>\n",
       "      <td>$27,236.00-$239,718.00</td>\n",
       "      <td>8.8</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3865</th>\n",
       "      <td>AOTF: Game Guides Writer - Remote</td>\n",
       "      <td>GAMURS Group</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>3 hours ago</td>\n",
       "      <td>Jobgether</td>\n",
       "      <td>[Jobgether]</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>*missing data*</td>\n",
       "      <td>Qualifications•Able to write a minimum of 25 a...</td>\n",
       "      <td>This a Full Remote job, the offer is available...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-09-27 08:00:21.557966</td>\n",
       "      <td>[$11, $60]</td>\n",
       "      <td>11.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>$11.00-$60.00</td>\n",
       "      <td>5.5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3942</th>\n",
       "      <td>Customer Retention Manager - Remote</td>\n",
       "      <td>Cvent</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>19 hours ago</td>\n",
       "      <td>Jobgether</td>\n",
       "      <td>[Jobgether]</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>55K–630K a year</td>\n",
       "      <td>Qualifications•Bachelor’s Degree or equivalent...</td>\n",
       "      <td>This a Full Remote job, the offer is available...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-09-29 00:00:25.488317</td>\n",
       "      <td>[$55,000-$63,0000]</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>630000.0</td>\n",
       "      <td>$55,000.00-$630,000.00</td>\n",
       "      <td>11.5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4070</th>\n",
       "      <td>Digital Marketing Specialist - Remote</td>\n",
       "      <td>2020 Companies</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>20 hours ago</td>\n",
       "      <td>Jobgether</td>\n",
       "      <td>[Jobgether, Learn4Good]</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>*missing data*</td>\n",
       "      <td>Qualifications•Proven work experience in digit...</td>\n",
       "      <td>This a Full Remote job, the offer is available...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-05 00:00:24.093386</td>\n",
       "      <td>[$50,000,, $30]</td>\n",
       "      <td>30.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>$30.00-$50,000.00</td>\n",
       "      <td>1666.7</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4087</th>\n",
       "      <td>Panera Bread Careers - Job Application for Pan...</td>\n",
       "      <td>Panera Bread</td>\n",
       "      <td>United States (+16 others)</td>\n",
       "      <td>22 hours ago</td>\n",
       "      <td>247 Careers For Freshers</td>\n",
       "      <td>[247 Careers For Freshers]</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>26,934–219,140 a year</td>\n",
       "      <td>Benefits•Salary and Benefits•Panera jobs provi...</td>\n",
       "      <td>If you desire to work in a company that manufa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-05 04:00:24.508423</td>\n",
       "      <td>[]</td>\n",
       "      <td>26934.0</td>\n",
       "      <td>219140.0</td>\n",
       "      <td>$26,934.00-$219,140.00</td>\n",
       "      <td>8.1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Role  \\\n",
       "180   Account Executive (Professional Information Bu...   \n",
       "438                                    Security Analyst   \n",
       "596                                  Side Hustle/Closer   \n",
       "932               Customer Service Representative (CSR)   \n",
       "1255                       Programming In New York City   \n",
       "1971                      Director of Performance Media   \n",
       "2159  Academic Dermatologist Specialized in Pigmente...   \n",
       "2483                                   Senior Recruiter   \n",
       "3704                   Senior Leader, Product Marketing   \n",
       "3791  DSW Careers in Columbus OH & Across the USA Jo...   \n",
       "3865                  AOTF: Game Guides Writer - Remote   \n",
       "3942                Customer Retention Manager - Remote   \n",
       "4070              Digital Marketing Specialist - Remote   \n",
       "4087  Panera Bread Careers - Job Application for Pan...   \n",
       "\n",
       "                               Company                    Location  \\\n",
       "180                          Dow Jones                New York, NY   \n",
       "438    Get It Recruit - Administrative                    Anywhere   \n",
       "596                            Bravado                    Anywhere   \n",
       "932                            soustar                   Bronx, NY   \n",
       "1255                 BuffTutor Network                New York, NY   \n",
       "1971        Get It Recruit - Marketing                    Anywhere   \n",
       "2159  Drug Information Association Inc                New York, NY   \n",
       "2483               Green Key Resources                New York, NY   \n",
       "3704        Get It Recruit - Marketing                    Anywhere   \n",
       "3791                   Designer Brands  United States (+11 others)   \n",
       "3865                      GAMURS Group                    Anywhere   \n",
       "3942                             Cvent                    Anywhere   \n",
       "4070                    2020 Companies                    Anywhere   \n",
       "4087                      Panera Bread  United States (+16 others)   \n",
       "\n",
       "              Posted                    Source          All Sources Listed  \\\n",
       "180     22 hours ago            Dow Jones Jobs                         NaN   \n",
       "438     21 hours ago                    Get.It                         NaN   \n",
       "596     17 hours ago                  LinkedIn                         NaN   \n",
       "932     19 hours ago                 Job Today                         NaN   \n",
       "1255    20 hours ago                 BuffTutor                         NaN   \n",
       "1971     8 hours ago                    Get.It                         NaN   \n",
       "2159     6 hours ago                                                   NaN   \n",
       "2483    10 hours ago                  LinkedIn                         NaN   \n",
       "3704    16 hours ago                    Get.It                    [Get.It]   \n",
       "3791  45 minutes ago  247 Careers For Freshers  [247 Careers For Freshers]   \n",
       "3865     3 hours ago                 Jobgether                 [Jobgether]   \n",
       "3942    19 hours ago                 Jobgether                 [Jobgether]   \n",
       "4070    20 hours ago                 Jobgether     [Jobgether, Learn4Good]   \n",
       "4087    22 hours ago  247 Careers For Freshers  [247 Careers For Freshers]   \n",
       "\n",
       "              Full / Part Time         Scraped Salary  \\\n",
       "180                  Full-time         *missing data*   \n",
       "438                  Full-time        40K–180K a year   \n",
       "596    Full-time and Part-time         *missing data*   \n",
       "932                  Full-time         *missing data*   \n",
       "1255  Part-time and Contractor          15–60 an hour   \n",
       "1971                 Full-time        55K–172K a year   \n",
       "2159                                 150K–500K a year   \n",
       "2483                 Full-time        45K–250K a year   \n",
       "3704                 Full-time        55K–172K a year   \n",
       "3791                 Full-time  27,236–239,718 a year   \n",
       "3865                 Full-time         *missing data*   \n",
       "3942                 Full-time        55K–630K a year   \n",
       "4070                 Full-time         *missing data*   \n",
       "4087                 Full-time  26,934–219,140 a year   \n",
       "\n",
       "                                         Job Highlights  \\\n",
       "180   Qualifications•An ability to develop and imple...   \n",
       "438   Qualifications•Proficient technical skills and...   \n",
       "596   Responsibilities•Strategizing with team member...   \n",
       "932                                      *missing data*   \n",
       "1255  Qualifications•Have at least a 3.0 or better m...   \n",
       "1971  Qualifications•Strong leadership skills with e...   \n",
       "2159  Qualifications•Applicants must have pigmented ...   \n",
       "2483  Qualifications•BA/BS Degree in Accounting, Bus...   \n",
       "3704  Qualifications•Strong coordination, stakeholde...   \n",
       "3791  Qualifications•Your resume proves you in your ...   \n",
       "3865  Qualifications•Able to write a minimum of 25 a...   \n",
       "3942  Qualifications•Bachelor’s Degree or equivalent...   \n",
       "4070  Qualifications•Proven work experience in digit...   \n",
       "4087  Benefits•Salary and Benefits•Panera jobs provi...   \n",
       "\n",
       "                                        Job Description  \\\n",
       "180   Job Description:About us:\\n\\nDow Jones is a gl...   \n",
       "438   Summary Description:\\n\\nWe are seeking an expe...   \n",
       "596   (Side-Gig) Side Hustle/Closer\\n\\nUnited States...   \n",
       "932                                      *missing data*   \n",
       "1255  BuffTutor is a network of experienced and pass...   \n",
       "1971  Director of Performance Media - Remote Opportu...   \n",
       "2159  Internal Number: 67287\\n\\nPay Range...\\n\\n$150...   \n",
       "2483  POSITION OVERVIEW\\n\\nGreen Key Resources is cu...   \n",
       "3704  Summary Description:\\nAlgolia is seeking a Sen...   \n",
       "3791  If you are interested to work in retail indust...   \n",
       "3865  This a Full Remote job, the offer is available...   \n",
       "3942  This a Full Remote job, the offer is available...   \n",
       "4070  This a Full Remote job, the offer is available...   \n",
       "4087  If you desire to work in a company that manufa...   \n",
       "\n",
       "                                         Any Other Text  \\\n",
       "180                                                 NaN   \n",
       "438                                                 NaN   \n",
       "596                                                 NaN   \n",
       "932   Empresa latinoamericana busca personal para ex...   \n",
       "1255                                                NaN   \n",
       "1971                                                NaN   \n",
       "2159                                                NaN   \n",
       "2483                                                NaN   \n",
       "3704                                                NaN   \n",
       "3791                                                NaN   \n",
       "3865                                                NaN   \n",
       "3942                                                NaN   \n",
       "4070                                                NaN   \n",
       "4087                                                NaN   \n",
       "\n",
       "                    Date Scraped                  Salary From Text  \\\n",
       "180                          NaN               [$50,000, $180,000]   \n",
       "438                          NaN                                []   \n",
       "596                          NaN                      [$100, 1000]   \n",
       "932   2023-09-15 20:01:33.591285                  [$1,000, $3,500]   \n",
       "1255  2023-09-16 09:01:52.937797                                []   \n",
       "1971  2023-09-17 18:01:21.811309                              [$1]   \n",
       "2159  2023-09-18 03:01:37.580887  [$150,000-$500,000, $150K-$510K]   \n",
       "2483  2023-09-18 21:01:59.182227                                []   \n",
       "3704  2023-09-21 06:01:48.035545                                []   \n",
       "3791  2023-09-23 18:00:18.022149                                []   \n",
       "3865  2023-09-27 08:00:21.557966                        [$11, $60]   \n",
       "3942  2023-09-29 00:00:25.488317                [$55,000-$63,0000]   \n",
       "4070  2023-10-05 00:00:24.093386                   [$50,000,, $30]   \n",
       "4087  2023-10-05 04:00:24.508423                                []   \n",
       "\n",
       "     Salary Lower Bound Salary Upper Bound             Salary Range  \\\n",
       "180             50000.0           180000.0   $50,000.00-$180,000.00   \n",
       "438             40000.0           180000.0   $40,000.00-$180,000.00   \n",
       "596               100.0             1000.0        $100.00-$1,000.00   \n",
       "932              1000.0             3500.0      $1,000.00-$3,500.00   \n",
       "1255               15.0               60.0            $15.00-$60.00   \n",
       "1971            55000.0           172000.0   $55,000.00-$172,000.00   \n",
       "2159           150000.0           500000.0  $150,000.00-$500,000.00   \n",
       "2483            45000.0           250000.0   $45,000.00-$250,000.00   \n",
       "3704            55000.0           172000.0   $55,000.00-$172,000.00   \n",
       "3791            27236.0           239718.0   $27,236.00-$239,718.00   \n",
       "3865               11.0               60.0            $11.00-$60.00   \n",
       "3942            55000.0           630000.0   $55,000.00-$630,000.00   \n",
       "4070               30.0            50000.0        $30.00-$50,000.00   \n",
       "4087            26934.0           219140.0   $26,934.00-$219,140.00   \n",
       "\n",
       "     Salary Ratio Notes  \n",
       "180           3.6        \n",
       "438           4.5        \n",
       "596          10.0        \n",
       "932           3.5        \n",
       "1255          4.0        \n",
       "1971          3.1        \n",
       "2159          3.3        \n",
       "2483          5.6        \n",
       "3704          3.1        \n",
       "3791          8.8        \n",
       "3865          5.5        \n",
       "3942         11.5        \n",
       "4070       1666.7        \n",
       "4087          8.1        "
      ]
     },
     "execution_count": 1871,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at salary ratios of over 3 to look for potential errors\n",
    "\n",
    "google_jobs_with_salaries = google_jobs_df_cleaned_test[(google_jobs_df_cleaned_test['Salary Ratio'] != '*no salary found*') & (google_jobs_df_cleaned_test['Salary Ratio'] != '*salary ambiguous*')]\n",
    "google_jobs_with_salaries[google_jobs_with_salaries['Salary Ratio'] > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1868,
   "id": "37d8a578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating Notes column\n",
    "\n",
    "google_jobs_df_cleaned_test['Notes'] = '' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1873,
   "id": "695ba090",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If you desire to work in a company that manufactures bakery products then do not miss the chance to apply for Panera Bread Careers. They are currently receiving job applications from both experienced professionals and newcomers. You must be sincere, creative, loyal, hardworking and self-motivated to get a position in this firm. They are providing employment opportunities to the people of... Michigan, Illinois, Virginia, Ohio, Florida and across the USA.\\n\\nFor More Top Organization Jobs: Click Here\\n\\nCompany Name:\\n\\nPanera Bread\\n\\nExperience:\\n\\nMandatory\\n\\nEducation:\\n\\nEquivalent Degree\\n\\nSalary Range:\\n\\nDepending Upon Designation\\n\\nBenefits:\\n\\nStandard Benefits\\n\\nNationality:\\n\\nSelective\\n\\nEmployment Type:\\n\\nFull-time\\n\\nJob Location:\\n\\nUnited States\\n\\nPosted Date:\\n\\nOctober 4th, 2023\\n\\nPanera Bread Careers Announced New Jobs Apply Online\\n\\nAbout Panera Bread\\n\\nPanera Bread Company is headquartered in Sunset Hills, Missouri which is a suburb of St. Louis. It has over 2000 restaurants. They deal with salads, soups, sandwiches, pasta, bakery items, and drinks. It is known as “Saint Louis Bread Company” in the region of Great Saint Louis which has more than 100 stores. This organization also owns Au Bon Pain. This place offers the most delicious baked items, pastries, cookies, croissants, muffins, and brownies. It also provides Panera Kids, froze iced drinks, lemonade, coffee, tea, fruit smoothies, espresso drinks, and hot chocolate. It has become the finest performing restaurant stock in the country. It was once the largest Wi-Fi Hotspots provider in the USA. It has more than 50,000 employees in all over the world.\\n\\nList of Available Vacant Positions (New Updates)\\n• Shift Supervisor\\n• Catering Coordinator\\n• Assistant Manager\\n• Delivery Driver\\n• Night Baker\\n• Restaurant Manager\\n• Cafe Associate\\n• Cashier\\n• Overnight Baker\\n• Overnight Baker\\n\\nSalary and Benefits\\n\\nPanera jobs provide basic facilities and perks to their workers. Before applying to this organization, it is important to take this into account.\\n• Great Cultural Values\\n• Flexible Schedules\\n• PTO accumulation for full time\\n• Uniform\\n• Helpful Management\\n• Better Pay Scale\\n• Use of Technological Advancements\\n• Good Work and Life Balance\\n• Fine Job Security\\n• Employee Discounts\\n• Disco\\n• unts on Lunch\\n\\nHow to Apply for Panera Bread Careers?\\n\\nIf you wish to apply for Panera Bread Careers then hit the button below and submit your CV online today. By clicking on this option, you will automatically be redirected to the main company’s profile page. Your resume is supposed to meet all the standards and look quite informative and to the point. Its summary should contain the entire points about you regarding your likes, dislikes, requirements for the professional work environment, expectations, etc. as this is your right.\\n\\nSubmit CV Online\\n\\nJob Title\\n\\nLocation\\n\\nTeam Manager\\n\\nBrookfield, WI, US\\n\\nCDL A Driver\\n\\nJessup, MD, US\\n\\nCashier\\n\\nBillings, MT, US\\n\\nDrive Thru Cashier\\n\\nKalispell, MT, US\\n\\nBarista\\n\\nBillings, MT, US\\n\\nSales Coordinator\\n\\nKalispell, MT, US\\n\\nSenior Manager\\n\\nUS'"
      ]
     },
     "execution_count": 1873,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_jobs_df_cleaned_test['Job Description'][4087]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1869,
   "id": "35760922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually cleaning any errors that were detected due to very high salary ratio\n",
    "\n",
    "update_salary(google_jobs_df_cleaned_test, 100000, None, 119, 'Removed bonus')\n",
    "update_salary(google_jobs_df_cleaned_test, 25, 30, 173, 'Online, found range $25-30 listed, but was pulled in as $2-$30 for some reason (Misc)')\n",
    "update_salary(google_jobs_df_cleaned_test, 115000, None, 494, 'Removed bonus')\n",
    "update_salary(google_jobs_df_cleaned_test, None, None, 635, 'Removed non-salary monetary value(s)')\n",
    "# should try to fix this error?\n",
    "update_salary(google_jobs_df_cleaned_test, 15, 20, 1145, 'Corrected error caused by cleaning code')\n",
    "update_salary(google_jobs_df_cleaned_test, 47000, 48000, 1416, 'Corrected typo')\n",
    "update_salary(google_jobs_df_cleaned_test, 350, None, 1724, 'Multiple ranges, selected one')\n",
    "update_salary(google_jobs_df_cleaned_test, 26.50, None, 2007, 'Removed bonus')\n",
    "update_salary(google_jobs_df_cleaned_test, 100000, None, 2017, 'Removed non-salary monetary value(s)')\n",
    "# might be able to automate this problem away (second values not listed with $)\n",
    "update_salary(google_jobs_df_cleaned_test, 30900, 52000, 2074, 'Two ranges included, manually selected one of the two ranges') \n",
    "update_salary(google_jobs_df_cleaned_test, 100000, 110000, 2186, 'User listed salary in an atypical manner: $100-$110,000 (Misc)') \n",
    "update_salary(google_jobs_df_cleaned_test, 56511, 70639, 2189, 'Corrected typo') \n",
    "update_salary(google_jobs_df_cleaned_test, 2098, None, 2450, 'Removed bonus')\n",
    "update_salary(google_jobs_df_cleaned_test, 3000, None, 2468, 'Multiple ranges, selected one')\n",
    "# weigh solutions for this that don't pull in non-salary values\n",
    "update_salary(google_jobs_df_cleaned_test, 600000, 1000000, 2488, '$1M not properly recognized by code') \n",
    "update_salary(google_jobs_df_cleaned_test, 140000, 165000, 2637, 'Corrected typo')\n",
    "update_salary(google_jobs_df_cleaned_test, 67500, 101000, 2643, 'Corrected typo')\n",
    "update_salary(google_jobs_df_cleaned_test, 17, None, 2776, 'Removed non-salary monetary value(s)')\n",
    "update_salary(google_jobs_df_cleaned_test, None, None, 2872, 'Removed non-salary monetary value(s)')\n",
    "update_salary(google_jobs_df_cleaned_test, 29.2, None, 2891, 'Removed bonus')\n",
    "update_salary(google_jobs_df_cleaned_test, None, None, 3363, 'Removed non-salary monetary value(s)')\n",
    "update_salary(google_jobs_df_cleaned_test, 10, None, 3456, 'Removed non-salary monetary value(s)')\n",
    "update_salary(google_jobs_df_cleaned_test, None, None, 3459, 'Removed non-salary monetary value(s)')\n",
    "update_salary(google_jobs_df_cleaned_test, 33000, 41000, 3789, 'Corrected typo')\n",
    "update_salary(google_jobs_df_cleaned_test, None, None, 3845, 'Removed non-salary monetary value(s)')\n",
    "update_salary(google_jobs_df_cleaned_test, 50000, None, 4070, 'Removed non-salary monetary value(s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1877,
   "id": "63dee631",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Role</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Posted</th>\n",
       "      <th>Source</th>\n",
       "      <th>All Sources Listed</th>\n",
       "      <th>Full / Part Time</th>\n",
       "      <th>Scraped Salary</th>\n",
       "      <th>Job Highlights</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Any Other Text</th>\n",
       "      <th>Date Scraped</th>\n",
       "      <th>Salary From Text</th>\n",
       "      <th>Salary Lower Bound</th>\n",
       "      <th>Salary Upper Bound</th>\n",
       "      <th>Salary Range</th>\n",
       "      <th>Salary Ratio</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>Coordinator, Partnership Marketing</td>\n",
       "      <td>Major League Soccer</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>11 hours ago</td>\n",
       "      <td>CareerBuilder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>*missing data*</td>\n",
       "      <td>Qualifications•Bachelor’s Degree•1+ years of e...</td>\n",
       "      <td>Overview\\n\\nReports To...\\n\\nSenior Manager, P...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[45000.0, 55000.0, 500.0]</td>\n",
       "      <td>*salary ambiguous*</td>\n",
       "      <td>*salary ambiguous*</td>\n",
       "      <td>*salary ambiguous*</td>\n",
       "      <td>*salary ambiguous*</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>Cdl local truck driver</td>\n",
       "      <td>SalSon</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>13 hours ago</td>\n",
       "      <td>Talent.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>*missing data*</td>\n",
       "      <td>Qualifications•Current CDL-A•Minimum 2 years r...</td>\n",
       "      <td>At SalSon, our CDL A Line Haul Drivers are at ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1250.0, 1350.0, 60.0, 15.0, 40.0, 100.0]</td>\n",
       "      <td>*salary ambiguous*</td>\n",
       "      <td>*salary ambiguous*</td>\n",
       "      <td>*salary ambiguous*</td>\n",
       "      <td>*salary ambiguous*</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>Appliance and Refrigeration Repair Technician</td>\n",
       "      <td>Labor Finders</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>23 hours ago</td>\n",
       "      <td>ZipRecruiter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>*missing data*</td>\n",
       "      <td>Qualifications•You like solving problems - Eac...</td>\n",
       "      <td>Appliance and Refrigeration Repair Technician ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[18.0, 30.0, 4000.0, 6.0]</td>\n",
       "      <td>*salary ambiguous*</td>\n",
       "      <td>*salary ambiguous*</td>\n",
       "      <td>*salary ambiguous*</td>\n",
       "      <td>*salary ambiguous*</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>Virtual Data Entry Clerk</td>\n",
       "      <td>FocusGroupJobs</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>14 hours ago</td>\n",
       "      <td>WayUp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-time and Part-time</td>\n",
       "      <td>*missing data*</td>\n",
       "      <td>Qualifications•Computer with internet access•Q...</td>\n",
       "      <td>We appreciate you checking us out! Work At Hom...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[35.0, 250.0, 3000.0]</td>\n",
       "      <td>*salary ambiguous*</td>\n",
       "      <td>*salary ambiguous*</td>\n",
       "      <td>*salary ambiguous*</td>\n",
       "      <td>*salary ambiguous*</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>Entry level sales representative</td>\n",
       "      <td>Power Home Remodeling</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>16 hours ago</td>\n",
       "      <td>Talent.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>*missing data*</td>\n",
       "      <td>Qualifications•Highly developed interpersonal,...</td>\n",
       "      <td>$4,000 Sign on Bonus\\n\\nEntry-Level Sales Repr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[4000.0, 45000.0, 60000.0, 3000.0]</td>\n",
       "      <td>*salary ambiguous*</td>\n",
       "      <td>*salary ambiguous*</td>\n",
       "      <td>*salary ambiguous*</td>\n",
       "      <td>*salary ambiguous*</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4024</th>\n",
       "      <td>Customer Success Manager, K12 EdTech - Remote</td>\n",
       "      <td>Partner in Publishing</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>24 hours ago</td>\n",
       "      <td>Jobgether</td>\n",
       "      <td>[Jobgether]</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>*missing data*</td>\n",
       "      <td>Qualifications•2+ years experience as a CSM or...</td>\n",
       "      <td>This a Full Remote job, the offer is available...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-04 08:00:37.556776</td>\n",
       "      <td>[60.0k, 70.0k, 80.0k, 90.0k]</td>\n",
       "      <td>*salary ambiguous*</td>\n",
       "      <td>*salary ambiguous*</td>\n",
       "      <td>*salary ambiguous*</td>\n",
       "      <td>*salary ambiguous*</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4050</th>\n",
       "      <td>Software Engineer - Remote</td>\n",
       "      <td>Multi Media, LLC</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>12 hours ago</td>\n",
       "      <td>Jobgether</td>\n",
       "      <td>[Jobgether]</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>*missing data*</td>\n",
       "      <td>Qualifications•We are seeking a Python expert,...</td>\n",
       "      <td>This a Full Remote job, the offer is available...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-04 20:00:20.662324</td>\n",
       "      <td>[125.0k, 117000.0k, 176000.0k]</td>\n",
       "      <td>*salary ambiguous*</td>\n",
       "      <td>*salary ambiguous*</td>\n",
       "      <td>*salary ambiguous*</td>\n",
       "      <td>*salary ambiguous*</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4063</th>\n",
       "      <td>Software Engineer - Remote</td>\n",
       "      <td>Multi Media, LLC</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>16 hours ago</td>\n",
       "      <td>Jobgether</td>\n",
       "      <td>[Jobgether]</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>*missing data*</td>\n",
       "      <td>Qualifications•We are seeking a Python expert,...</td>\n",
       "      <td>This a Full Remote job, the offer is available...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-05 00:00:20.683702</td>\n",
       "      <td>[125.0k, 117000.0k, 176000.0k]</td>\n",
       "      <td>*salary ambiguous*</td>\n",
       "      <td>*salary ambiguous*</td>\n",
       "      <td>*salary ambiguous*</td>\n",
       "      <td>*salary ambiguous*</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4079</th>\n",
       "      <td>Software Engineer - Remote</td>\n",
       "      <td>Multi Media, LLC</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>20 hours ago</td>\n",
       "      <td>Jobgether</td>\n",
       "      <td>[Jobgether]</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>*missing data*</td>\n",
       "      <td>Qualifications•We are seeking a Python expert,...</td>\n",
       "      <td>This a Full Remote job, the offer is available...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-05 04:00:20.296485</td>\n",
       "      <td>[125.0k, 117000.0k, 176000.0k]</td>\n",
       "      <td>*salary ambiguous*</td>\n",
       "      <td>*salary ambiguous*</td>\n",
       "      <td>*salary ambiguous*</td>\n",
       "      <td>*salary ambiguous*</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4093</th>\n",
       "      <td>Software Engineer - Remote</td>\n",
       "      <td>Multi Media, LLC</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>24 hours ago</td>\n",
       "      <td>Jobgether</td>\n",
       "      <td>[Jobgether]</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>*missing data*</td>\n",
       "      <td>Qualifications•We are seeking a Python expert,...</td>\n",
       "      <td>This a Full Remote job, the offer is available...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-05 08:00:19.912299</td>\n",
       "      <td>[125.0k, 117000.0k, 176000.0k]</td>\n",
       "      <td>*salary ambiguous*</td>\n",
       "      <td>*salary ambiguous*</td>\n",
       "      <td>*salary ambiguous*</td>\n",
       "      <td>*salary ambiguous*</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Role                Company  \\\n",
       "625              Coordinator, Partnership Marketing    Major League Soccer   \n",
       "669                          Cdl local truck driver                 SalSon   \n",
       "671   Appliance and Refrigeration Repair Technician          Labor Finders   \n",
       "749                        Virtual Data Entry Clerk         FocusGroupJobs   \n",
       "760                Entry level sales representative  Power Home Remodeling   \n",
       "...                                             ...                    ...   \n",
       "4024  Customer Success Manager, K12 EdTech - Remote  Partner in Publishing   \n",
       "4050                     Software Engineer - Remote       Multi Media, LLC   \n",
       "4063                     Software Engineer - Remote       Multi Media, LLC   \n",
       "4079                     Software Engineer - Remote       Multi Media, LLC   \n",
       "4093                     Software Engineer - Remote       Multi Media, LLC   \n",
       "\n",
       "          Location        Posted         Source All Sources Listed  \\\n",
       "625   New York, NY  11 hours ago  CareerBuilder                NaN   \n",
       "669   New York, NY  13 hours ago     Talent.com                NaN   \n",
       "671   New York, NY  23 hours ago   ZipRecruiter                NaN   \n",
       "749   New York, NY  14 hours ago          WayUp                NaN   \n",
       "760   New York, NY  16 hours ago     Talent.com                NaN   \n",
       "...            ...           ...            ...                ...   \n",
       "4024      Anywhere  24 hours ago      Jobgether        [Jobgether]   \n",
       "4050      Anywhere  12 hours ago      Jobgether        [Jobgether]   \n",
       "4063      Anywhere  16 hours ago      Jobgether        [Jobgether]   \n",
       "4079      Anywhere  20 hours ago      Jobgether        [Jobgether]   \n",
       "4093      Anywhere  24 hours ago      Jobgether        [Jobgether]   \n",
       "\n",
       "             Full / Part Time  Scraped Salary  \\\n",
       "625                 Full-time  *missing data*   \n",
       "669                 Full-time  *missing data*   \n",
       "671                 Full-time  *missing data*   \n",
       "749   Full-time and Part-time  *missing data*   \n",
       "760                 Full-time  *missing data*   \n",
       "...                       ...             ...   \n",
       "4024                Full-time  *missing data*   \n",
       "4050                Full-time  *missing data*   \n",
       "4063                Full-time  *missing data*   \n",
       "4079                Full-time  *missing data*   \n",
       "4093                Full-time  *missing data*   \n",
       "\n",
       "                                         Job Highlights  \\\n",
       "625   Qualifications•Bachelor’s Degree•1+ years of e...   \n",
       "669   Qualifications•Current CDL-A•Minimum 2 years r...   \n",
       "671   Qualifications•You like solving problems - Eac...   \n",
       "749   Qualifications•Computer with internet access•Q...   \n",
       "760   Qualifications•Highly developed interpersonal,...   \n",
       "...                                                 ...   \n",
       "4024  Qualifications•2+ years experience as a CSM or...   \n",
       "4050  Qualifications•We are seeking a Python expert,...   \n",
       "4063  Qualifications•We are seeking a Python expert,...   \n",
       "4079  Qualifications•We are seeking a Python expert,...   \n",
       "4093  Qualifications•We are seeking a Python expert,...   \n",
       "\n",
       "                                        Job Description Any Other Text  \\\n",
       "625   Overview\\n\\nReports To...\\n\\nSenior Manager, P...            NaN   \n",
       "669   At SalSon, our CDL A Line Haul Drivers are at ...            NaN   \n",
       "671   Appliance and Refrigeration Repair Technician ...            NaN   \n",
       "749   We appreciate you checking us out! Work At Hom...            NaN   \n",
       "760   $4,000 Sign on Bonus\\n\\nEntry-Level Sales Repr...            NaN   \n",
       "...                                                 ...            ...   \n",
       "4024  This a Full Remote job, the offer is available...            NaN   \n",
       "4050  This a Full Remote job, the offer is available...            NaN   \n",
       "4063  This a Full Remote job, the offer is available...            NaN   \n",
       "4079  This a Full Remote job, the offer is available...            NaN   \n",
       "4093  This a Full Remote job, the offer is available...            NaN   \n",
       "\n",
       "                    Date Scraped                           Salary From Text  \\\n",
       "625                          NaN                  [45000.0, 55000.0, 500.0]   \n",
       "669                          NaN  [1250.0, 1350.0, 60.0, 15.0, 40.0, 100.0]   \n",
       "671                          NaN                  [18.0, 30.0, 4000.0, 6.0]   \n",
       "749                          NaN                      [35.0, 250.0, 3000.0]   \n",
       "760                          NaN         [4000.0, 45000.0, 60000.0, 3000.0]   \n",
       "...                          ...                                        ...   \n",
       "4024  2023-10-04 08:00:37.556776               [60.0k, 70.0k, 80.0k, 90.0k]   \n",
       "4050  2023-10-04 20:00:20.662324             [125.0k, 117000.0k, 176000.0k]   \n",
       "4063  2023-10-05 00:00:20.683702             [125.0k, 117000.0k, 176000.0k]   \n",
       "4079  2023-10-05 04:00:20.296485             [125.0k, 117000.0k, 176000.0k]   \n",
       "4093  2023-10-05 08:00:19.912299             [125.0k, 117000.0k, 176000.0k]   \n",
       "\n",
       "      Salary Lower Bound  Salary Upper Bound        Salary Range  \\\n",
       "625   *salary ambiguous*  *salary ambiguous*  *salary ambiguous*   \n",
       "669   *salary ambiguous*  *salary ambiguous*  *salary ambiguous*   \n",
       "671   *salary ambiguous*  *salary ambiguous*  *salary ambiguous*   \n",
       "749   *salary ambiguous*  *salary ambiguous*  *salary ambiguous*   \n",
       "760   *salary ambiguous*  *salary ambiguous*  *salary ambiguous*   \n",
       "...                  ...                 ...                 ...   \n",
       "4024  *salary ambiguous*  *salary ambiguous*  *salary ambiguous*   \n",
       "4050  *salary ambiguous*  *salary ambiguous*  *salary ambiguous*   \n",
       "4063  *salary ambiguous*  *salary ambiguous*  *salary ambiguous*   \n",
       "4079  *salary ambiguous*  *salary ambiguous*  *salary ambiguous*   \n",
       "4093  *salary ambiguous*  *salary ambiguous*  *salary ambiguous*   \n",
       "\n",
       "            Salary Ratio Notes  \n",
       "625   *salary ambiguous*        \n",
       "669   *salary ambiguous*        \n",
       "671   *salary ambiguous*        \n",
       "749   *salary ambiguous*        \n",
       "760   *salary ambiguous*        \n",
       "...                  ...   ...  \n",
       "4024  *salary ambiguous*        \n",
       "4050  *salary ambiguous*        \n",
       "4063  *salary ambiguous*        \n",
       "4079  *salary ambiguous*        \n",
       "4093  *salary ambiguous*        \n",
       "\n",
       "[147 rows x 18 columns]"
      ]
     },
     "execution_count": 1877,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# taking a look at salaries deemed ambiguous to determine if they can be manually corrected\n",
    "\n",
    "google_jobs_df_cleaned_test[google_jobs_df_cleaned_test['Salary Range'] == '*salary ambiguous*']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1875,
   "id": "4181c207",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Benefits•$3354.44-$3715.13 wk (includes wage of ~$19.99-$29.00/hr and per diems if eligible)•~$799.44-$1160.13 weekly taxable income•~$2555 in non-taxable per diem (amount subject to eligibility & seasonal/annual adjustment)•$600 for 600 hours worked unlimited loyalty bonus•24/7 customer care line•Free employee assistance program (EAP)•$500 unlimited referral bonus•Day-one medical, dental, and vision insurance•401(k) with company contribution•Paid, private, pet-friendly housing•Licensure/certification reimbursement•Traveler discount program•Voluntary insurance benefits•Equal employment opportunity'"
      ]
     },
     "execution_count": 1875,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_jobs_df_cleaned_test['Job Highlights'][611]\n",
    "#google_jobs_df_cleaned_test['Job Description'][167]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1876,
   "id": "734fa03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Role</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Posted</th>\n",
       "      <th>Source</th>\n",
       "      <th>All Sources Listed</th>\n",
       "      <th>Full / Part Time</th>\n",
       "      <th>Scraped Salary</th>\n",
       "      <th>Job Highlights</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Any Other Text</th>\n",
       "      <th>Date Scraped</th>\n",
       "      <th>Salary From Text</th>\n",
       "      <th>Salary Lower Bound</th>\n",
       "      <th>Salary Upper Bound</th>\n",
       "      <th>Salary Range</th>\n",
       "      <th>Salary Ratio</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>Travel PICU (Pediatric Intensive Care Unit) RN...</td>\n",
       "      <td>Medical Solutions</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>9 hours ago</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>*missing data*</td>\n",
       "      <td>Benefits•$3354.44-$3715.13 wk (includes wage o...</td>\n",
       "      <td>$3354.44-$3715.13 wk (includes wage of ~$19.99...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[3354.4, 3715.1, 20.0, 29.0, 799.4, 1160.1, 25...</td>\n",
       "      <td>3354.44</td>\n",
       "      <td>3715.13</td>\n",
       "      <td>$3,354.44-$3,715.13</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Removed non-salary monetary value(s)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Role            Company  \\\n",
       "611  Travel PICU (Pediatric Intensive Care Unit) RN...  Medical Solutions   \n",
       "\n",
       "         Location       Posted Source All Sources Listed Full / Part Time  \\\n",
       "611  New York, NY  9 hours ago                       NaN                    \n",
       "\n",
       "     Scraped Salary                                     Job Highlights  \\\n",
       "611  *missing data*  Benefits•$3354.44-$3715.13 wk (includes wage o...   \n",
       "\n",
       "                                       Job Description Any Other Text  \\\n",
       "611  $3354.44-$3715.13 wk (includes wage of ~$19.99...            NaN   \n",
       "\n",
       "    Date Scraped                                   Salary From Text  \\\n",
       "611          NaN  [3354.4, 3715.1, 20.0, 29.0, 799.4, 1160.1, 25...   \n",
       "\n",
       "    Salary Lower Bound Salary Upper Bound         Salary Range Salary Ratio  \\\n",
       "611            3354.44            3715.13  $3,354.44-$3,715.13          1.1   \n",
       "\n",
       "                                    Notes  \n",
       "611  Removed non-salary monetary value(s)  "
      ]
     },
     "execution_count": 1876,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_salary(google_jobs_df_cleaned_test, 2524.84, 2796.32, 19, 'Removed non-salary monetary value(s)')\n",
    "update_salary(google_jobs_df_cleaned_test, 3200, None, 50, 'Removed non-salary monetary value(s)')\n",
    "update_salary(google_jobs_df_cleaned_test, 75, 150, 107, 'Multiple ranges, selected one')\n",
    "update_salary(google_jobs_df_cleaned_test, 2513.49, 2783.75, 143, 'Multiple ranges, selected one')\n",
    "update_salary(google_jobs_df_cleaned_test, 175000, 240000, 150, 'Removed bonus')\n",
    "update_salary(google_jobs_df_cleaned_test, 108100, 224600, 167, 'Ranges listed for multiple cities, chose NYC range')\n",
    "update_salary(google_jobs_df_cleaned_test, 2563.57, 2839.23, 195, 'Multiple ranges, selected one')\n",
    "update_salary(google_jobs_df_cleaned_test, 70, None, 316, 'Multiple ranges, selected one')\n",
    "update_salary(google_jobs_df_cleaned_test, 96000, 128000, 337, 'Ranges listed for multiple cities, chose NYC range')\n",
    "update_salary(google_jobs_df_cleaned_test, 28.40, 42.60, 338, 'Removed non-salary monetary value(s)')\n",
    "update_salary(google_jobs_df_cleaned_test, 141200, 188300, 360, 'Multiple ranges, selected one')\n",
    "update_salary(google_jobs_df_cleaned_test, 50000, 70000, 369, 'Removed bonus')\n",
    "update_salary(google_jobs_df_cleaned_test, 61200, 102000, 476, 'Multiple ranges, selected one')\n",
    "update_salary(google_jobs_df_cleaned_test, 51000, 55000, 519, 'Removed bonus')\n",
    "update_salary(google_jobs_df_cleaned_test, 160000, 180000, 521, 'Multiple ranges, selected one')\n",
    "update_salary(google_jobs_df_cleaned_test, 21.75, 26.30, 577, 'Removed non-salary monetary value(s)')\n",
    "update_salary(google_jobs_df_cleaned_test, 3354.44, 3715.13, 611, 'Removed non-salary monetary value(s)')\n",
    "\n",
    "google_jobs_df_cleaned_test[611:611+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1878,
   "id": "bbaf06a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['New York, NY', 'Anywhere', 'Brooklyn, NY', 'Bronx, NY',\n",
       "       'Long Island City, NY', 'New York, NY (+1 other)',\n",
       "       'New York, NY (+2 others)', 'LA GURDA ARPT, NY',\n",
       "       'ROCKAWAY BEAC, NY', 'Neponsit, NY', 'New York, NY (+19 others)',\n",
       "       'Manhattan, NY', 'Howard Beach, NY', 'United States (+5 others)',\n",
       "       'United States (+6 others)', 'United States (+11 others)',\n",
       "       'United States (+1 other)', 'United States (+2 others)',\n",
       "       'United States (+8 others)', 'United States (+3 others)',\n",
       "       'United States (+16 others)'], dtype=object)"
      ]
     },
     "execution_count": 1878,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_jobs_df_cleaned_test['Location'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1879,
   "id": "b2c9faa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ravram/opt/anaconda3/lib/python3.9/site-packages/IPython/core/displayhook.py:275: UserWarning: Output cache limit (currently 1000 entries) hit.\n",
      "Flushing oldest 200 entries.\n",
      "  warn('Output cache limit (currently {sz} entries) hit.\\n'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Talent.com</th>\n",
       "      <td>536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinkedIn</th>\n",
       "      <td>530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jobgether</th>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indeed</th>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trabajo.org</th>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZipRecruiter</th>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Source Unknown</th>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrabJobs</th>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snagajob</th>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BeBee</th>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Total\n",
       "Talent.com        536\n",
       "LinkedIn          530\n",
       "Jobgether         319\n",
       "Indeed            257\n",
       "Trabajo.org       256\n",
       "ZipRecruiter      252\n",
       "Source Unknown    245\n",
       "GrabJobs          232\n",
       "Snagajob          210\n",
       "BeBee             108"
      ]
     },
     "execution_count": 1879,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top job sources\n",
    "\n",
    "pd.DataFrame(google_jobs_df_cleaned_test['Source'].value_counts()).head(10).rename(columns={'Source':'Total'},index={'':'Source Unknown'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1880,
   "id": "d18813c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>% Share of Job Postings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Source</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Jobgether</th>\n",
       "      <td>21.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinkedIn</th>\n",
       "      <td>8.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indeed</th>\n",
       "      <td>6.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glassdoor</th>\n",
       "      <td>3.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Talent.com</th>\n",
       "      <td>3.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SimplyHired</th>\n",
       "      <td>3.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BeBee</th>\n",
       "      <td>3.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZipRecruiter</th>\n",
       "      <td>2.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CareerBuilder</th>\n",
       "      <td>2.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SaluteMyJob</th>\n",
       "      <td>1.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adzuna</th>\n",
       "      <td>1.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>My Stateline Jobs</th>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Star Job Search</th>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JobServe</th>\n",
       "      <td>1.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jobilize</th>\n",
       "      <td>1.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Learn4Good.com</th>\n",
       "      <td>1.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snagajob</th>\n",
       "      <td>1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York Jobs - Tarta.ai</th>\n",
       "      <td>1.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WAVY Jobs</th>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jooble</th>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          % Share of Job Postings\n",
       "Source                                           \n",
       "Jobgether                                   21.42\n",
       "LinkedIn                                     8.85\n",
       "Indeed                                       6.05\n",
       "Glassdoor                                    3.84\n",
       "Talent.com                                   3.78\n",
       "SimplyHired                                  3.32\n",
       "BeBee                                        3.32\n",
       "ZipRecruiter                                 2.93\n",
       "CareerBuilder                                2.02\n",
       "SaluteMyJob                                  1.69\n",
       "Adzuna                                       1.63\n",
       "My Stateline Jobs                            1.50\n",
       "Star Job Search                              1.50\n",
       "JobServe                                     1.30\n",
       "Jobilize                                     1.24\n",
       "Learn4Good.com                               1.17\n",
       "Snagajob                                     1.11\n",
       "New York Jobs - Tarta.ai                     1.11\n",
       "WAVY Jobs                                    0.98\n",
       "Jooble                                       0.98"
      ]
     },
     "execution_count": 1880,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at the market share each job source holds\n",
    "\n",
    "market_share_df = pd.DataFrame(round(100*((google_jobs_df_cleaned_test['All Sources Listed'].explode().value_counts()) / \n",
    "                                (len(google_jobs_df_cleaned_test['All Sources Listed'].dropna().explode()))),2)).rename(columns={'All Sources Listed':'% Share of Job Postings'})\n",
    "\n",
    "market_share_df.index.rename('Source', inplace=True)\n",
    "\n",
    "market_share_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1881,
   "id": "2c491165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    696.000000\n",
       "mean       2.206897\n",
       "std        2.057521\n",
       "min        1.000000\n",
       "25%        1.000000\n",
       "50%        1.000000\n",
       "75%        2.250000\n",
       "max        8.000000\n",
       "Name: All Sources Listed, dtype: float64"
      ]
     },
     "execution_count": 1881,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# descriptive stats about the number of sites Google Jobs finds a job posting on\n",
    "\n",
    "jobs_with_multiple_sources = google_jobs_df_cleaned_test[google_jobs_df_cleaned_test['All Sources Listed'].map(type) != float]\n",
    "\n",
    "jobs_with_multiple_sources['All Sources Listed'].apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1882,
   "id": "f8bdbccf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Salary Not Scraped</th>\n",
       "      <th>Total</th>\n",
       "      <th>% Salary Not Scraped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Talent.com</th>\n",
       "      <td>474</td>\n",
       "      <td>536</td>\n",
       "      <td>88.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinkedIn</th>\n",
       "      <td>467</td>\n",
       "      <td>530</td>\n",
       "      <td>88.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trabajo.org</th>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrabJobs</th>\n",
       "      <td>230</td>\n",
       "      <td>232</td>\n",
       "      <td>99.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BeBee</th>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SmartRecruiters Job Search</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SimplyHired</th>\n",
       "      <td>99</td>\n",
       "      <td>100</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Learn4Good.com</th>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "      <td>97.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CareerBuilder</th>\n",
       "      <td>45</td>\n",
       "      <td>48</td>\n",
       "      <td>93.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Salary Not Scraped  Total  % Salary Not Scraped\n",
       "Talent.com                                 474    536                 88.43\n",
       "LinkedIn                                   467    530                 88.11\n",
       "Trabajo.org                                256    256                100.00\n",
       "GrabJobs                                   230    232                 99.14\n",
       "BeBee                                      108    108                100.00\n",
       "SmartRecruiters Job Search                 100    100                100.00\n",
       "SimplyHired                                 99    100                 99.00\n",
       "Learn4Good.com                              48     49                 97.96\n",
       "CareerBuilder                               45     48                 93.75"
      ]
     },
     "execution_count": 1882,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sources with 40 or more job postings where 85% or more did not have a salary originally scraped\n",
    "# trying to identify the most impactful 'worst offenders'\n",
    "\n",
    "salary_not_scraped_df = pd.DataFrame((google_jobs_df_cleaned_test[google_jobs_df_cleaned_test['Scraped Salary'] == '*missing data*']['Source'].value_counts())).rename(columns={'Source':'Salary Not Scraped'})\n",
    "salary_not_scraped_df['Total'] = google_jobs_df_cleaned_test['Source'].value_counts()   \n",
    "salary_not_scraped_df['% Salary Not Scraped'] = round((100*(salary_not_scraped_df['Salary Not Scraped'] / salary_not_scraped_df['Total'])),2)\n",
    "salary_not_scraped_df.rename(index={'':'Source Unknown'},inplace=True)\n",
    "\n",
    "salary_not_scraped_df[(salary_not_scraped_df['% Salary Not Scraped'] > 85) & (salary_not_scraped_df['Total'] > 40)].sort_values('Total', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1883,
   "id": "72511a93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# google_jobs_df_cleaned_test[google_jobs_df_cleaned_test['Source'] == 'LinkedIn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1884,
   "id": "dc6a5412",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Without Salary</th>\n",
       "      <th>Total</th>\n",
       "      <th>% Without Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Trabajo.org</th>\n",
       "      <td>191</td>\n",
       "      <td>256</td>\n",
       "      <td>74.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BeBee</th>\n",
       "      <td>79</td>\n",
       "      <td>108</td>\n",
       "      <td>73.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SmartRecruiters Job Search</th>\n",
       "      <td>81</td>\n",
       "      <td>100</td>\n",
       "      <td>81.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Without Salary  Total  % Without Salary\n",
       "Trabajo.org                            191    256             74.61\n",
       "BeBee                                   79    108             73.15\n",
       "SmartRecruiters Job Search              81    100             81.00"
      ]
     },
     "execution_count": 1884,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sources with 40 or more job postings where 70% or more did not have any salary found after cleaning\n",
    "# trying to identify the most impactful 'worst offenders'\n",
    "\n",
    "salary_not_found_df = pd.DataFrame((google_jobs_df_cleaned_test[google_jobs_df_cleaned_test['Salary Ratio'] == '*no salary found*']['Source'].value_counts())).rename(columns={'Source':'Without Salary'})\n",
    "salary_not_found_df['Total'] = google_jobs_df_cleaned_test['Source'].value_counts()   \n",
    "salary_not_found_df['% Without Salary'] = round((100*(salary_not_found_df['Without Salary'] / salary_not_found_df['Total'])),2)\n",
    "salary_not_found_df.rename(index={'':'Source Unknown'},inplace=True)\n",
    "\n",
    "#salary_not_found_df.sort_values('Total', ascending=False).head(20)\n",
    "salary_not_found_df[(salary_not_found_df['% Without Salary'] > 70) & (salary_not_found_df['Total'] > 40)].sort_values('Total', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1885,
   "id": "1ff3cfad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Without Salary        4.0\n",
       "Total                 4.0\n",
       "% Without Salary    100.0\n",
       "Name: NYC Jobs - NYC.gov, dtype: float64"
      ]
     },
     "execution_count": 1885,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flag: 100% of jobs pulled from NYC.gov do not contain salaries\n",
    "\n",
    "salary_not_found_df.loc['NYC Jobs - NYC.gov']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1886,
   "id": "bcc4d93f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Without Salary</th>\n",
       "      <th>Total</th>\n",
       "      <th>% Without Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>City of New York</th>\n",
       "      <td>79</td>\n",
       "      <td>85</td>\n",
       "      <td>92.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Columbia University</th>\n",
       "      <td>33</td>\n",
       "      <td>62</td>\n",
       "      <td>53.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Care.com</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mediabistro</th>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>76.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jobot</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>5.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Memorial Sloan</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>6.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Morgan Stanley</th>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>42.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arrow Search Partners</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>8.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Whole Foods Market</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>18.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amazon</th>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>63.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trigyn</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Peak Organization Inc</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Northwell Health</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>70.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Insight Global</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>77.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Goodwin Recruiting</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>44.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Capital One</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>22.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hilton</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Centene Corporation</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Confidential</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AECOM</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>25.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Without Salary  Total  % Without Salary\n",
       "City of New York                       79     85             92.94\n",
       "Columbia University                    33     62             53.23\n",
       "Care.com                                2     25              8.00\n",
       "Mediabistro                            13     17             76.47\n",
       "Jobot                                   1     17              5.88\n",
       "Memorial Sloan                          1     16              6.25\n",
       "Morgan Stanley                          6     14             42.86\n",
       "Arrow Search Partners                   1     12              8.33\n",
       "Whole Foods Market                      2     11             18.18\n",
       "Amazon                                  7     11             63.64\n",
       "Trigyn                                 11     11            100.00\n",
       "The Peak Organization Inc               3     10             30.00\n",
       "Northwell Health                        7     10             70.00\n",
       "Insight Global                          7      9             77.78\n",
       "Goodwin Recruiting                      4      9             44.44\n",
       "Capital One                             2      9             22.22\n",
       "Hilton                                  9      9            100.00\n",
       "Centene Corporation                     9      9            100.00\n",
       "Confidential                            4      8             50.00\n",
       "AECOM                                   2      8             25.00"
      ]
     },
     "execution_count": 1886,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# % of entries from these companies without salaries \n",
    "\n",
    "salary_not_found_df = pd.DataFrame((google_jobs_df_cleaned_test[google_jobs_df_cleaned_test['Salary Ratio'] == '*no salary found*']['Company'].value_counts())).rename(columns={'Company':'Without Salary'})\n",
    "salary_not_found_df['Total'] = google_jobs_df_cleaned_test['Company'].value_counts()   \n",
    "salary_not_found_df['% Without Salary'] = round((100*(salary_not_found_df['Without Salary'] / salary_not_found_df['Total'])),2)\n",
    "\n",
    "salary_not_found_df.sort_values('Total', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1887,
   "id": "0ec175a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Without Salary</th>\n",
       "      <th>Total</th>\n",
       "      <th>% Without Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Administrative Assistant</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bartender</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>87.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Senior Accountant</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>42.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Business Intelligence Analyst - Remote</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stock associate</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>71.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product Manager - Remote</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>71.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Warehouse associate</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Business Analyst</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Office assistant</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>83.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Customer Service Representative</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Receptionist</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>66.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Account Manager</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>33.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Project Manager</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>40.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retail sales associate</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>80.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Administrative assistant</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>20.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Software Engineer - Remote</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>20.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Developer IV - Software - Remote</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pt cashier</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Internal Auditor II - Remote</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Associate Project Accountant - Remote</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Without Salary  Total  \\\n",
       "Administrative Assistant                             1     10   \n",
       "Bartender                                            7      8   \n",
       "Senior Accountant                                    3      7   \n",
       "Business Intelligence Analyst - Remote               7      7   \n",
       "Stock associate                                      5      7   \n",
       "Product Manager - Remote                             5      7   \n",
       "Warehouse associate                                  6      6   \n",
       "Business Analyst                                     6      6   \n",
       "Office assistant                                     5      6   \n",
       "Customer Service Representative                      1      6   \n",
       "Receptionist                                         4      6   \n",
       "Account Manager                                      2      6   \n",
       "Project Manager                                      2      5   \n",
       "Retail sales associate                               4      5   \n",
       "Administrative assistant                             1      5   \n",
       "Software Engineer - Remote                           1      5   \n",
       "Developer IV - Software - Remote                     5      5   \n",
       "Pt cashier                                           5      5   \n",
       "Internal Auditor II - Remote                         5      5   \n",
       "Associate Project Accountant - Remote                5      5   \n",
       "\n",
       "                                        % Without Salary  \n",
       "Administrative Assistant                           10.00  \n",
       "Bartender                                          87.50  \n",
       "Senior Accountant                                  42.86  \n",
       "Business Intelligence Analyst - Remote            100.00  \n",
       "Stock associate                                    71.43  \n",
       "Product Manager - Remote                           71.43  \n",
       "Warehouse associate                               100.00  \n",
       "Business Analyst                                  100.00  \n",
       "Office assistant                                   83.33  \n",
       "Customer Service Representative                    16.67  \n",
       "Receptionist                                       66.67  \n",
       "Account Manager                                    33.33  \n",
       "Project Manager                                    40.00  \n",
       "Retail sales associate                             80.00  \n",
       "Administrative assistant                           20.00  \n",
       "Software Engineer - Remote                         20.00  \n",
       "Developer IV - Software - Remote                  100.00  \n",
       "Pt cashier                                        100.00  \n",
       "Internal Auditor II - Remote                      100.00  \n",
       "Associate Project Accountant - Remote             100.00  "
      ]
     },
     "execution_count": 1887,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# % of entries from these roles without salaries \n",
    "\n",
    "salary_not_found_df = pd.DataFrame((google_jobs_df_cleaned_test[google_jobs_df_cleaned_test['Salary Ratio'] == '*no salary found*']['Role'].value_counts())).rename(columns={'Role':'Without Salary'})\n",
    "salary_not_found_df['Total'] = google_jobs_df_cleaned_test['Role'].value_counts()   \n",
    "salary_not_found_df['% Without Salary'] = round((100*(salary_not_found_df['Without Salary'] / salary_not_found_df['Total'])),2)\n",
    "\n",
    "salary_not_found_df.sort_values('Total', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1889,
   "id": "fe6df639",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.395e+03, 4.660e+02, 1.650e+02, 7.400e+01, 2.000e+01, 5.000e+00,\n",
       "        5.000e+00, 1.000e+00, 2.000e+00, 1.000e+00, 0.000e+00, 1.000e+00,\n",
       "        0.000e+00, 0.000e+00, 2.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00,\n",
       "        1.000e+00]),\n",
       " array([1.   , 1.312, 1.624, 1.936, 2.248, 2.56 , 2.872, 3.184, 3.496,\n",
       "        3.808, 4.12 , 4.432, 4.744, 5.056, 5.368, 5.68 , 5.992, 6.304,\n",
       "        6.616, 6.928, 7.24 , 7.552, 7.864, 8.176, 8.488, 8.8  ]),\n",
       " <BarContainer object of 25 artists>)"
      ]
     },
     "execution_count": 1889,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# taking a look at the salary ratio distribution (outlier over 10 removed)\n",
    "\n",
    "salaries = google_jobs_df_cleaned_test[(google_jobs_df_cleaned_test['Salary Ratio'] != '*no salary found*') & (google_jobs_df_cleaned_test['Salary Range'] != '*salary ambiguous*')]['Salary Ratio'].to_list()\n",
    "salaries_filtered = list(filter(lambda x: x < 10, salaries))\n",
    "\n",
    "plt.hist(salaries_filtered, bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1890,
   "id": "8d1198aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([641., 337., 278., 139., 260., 125., 162.,   0.,  37.,  47.,  49.,\n",
       "         17.,   8.,  15.,   0.,   5.,   3.,   2.,   2.,   1.]),\n",
       " array([1. , 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2. , 2.1, 2.2,\n",
       "        2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.9, 3. ]),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 1890,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# taking a closer look at the salary ratio distribution below 3\n",
    "\n",
    "salaries_filtered = list(filter(lambda x: x <= 3, salaries))\n",
    "\n",
    "plt.hist(salaries_filtered, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1891,
   "id": "278236a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2142.000000\n",
       "mean        2.083333\n",
       "std        35.987492\n",
       "min         1.000000\n",
       "25%         1.000000\n",
       "50%         1.200000\n",
       "75%         1.400000\n",
       "max      1666.700000\n",
       "Name: Salary Ratio, dtype: float64"
      ]
     },
     "execution_count": 1891,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quartiles for salary ratio\n",
    "\n",
    "google_jobs_df_cleaned_test[(google_jobs_df_cleaned_test['Salary Ratio'] != '*no salary found*') & (google_jobs_df_cleaned_test['Salary Range'] != '*salary ambiguous*')]['Salary Ratio'].astype(float).describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1892,
   "id": "22e91bef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Role</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Posted</th>\n",
       "      <th>Source</th>\n",
       "      <th>All Sources Listed</th>\n",
       "      <th>Full / Part Time</th>\n",
       "      <th>Scraped Salary</th>\n",
       "      <th>Job Highlights</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Any Other Text</th>\n",
       "      <th>Date Scraped</th>\n",
       "      <th>Salary From Text</th>\n",
       "      <th>Salary Lower Bound</th>\n",
       "      <th>Salary Upper Bound</th>\n",
       "      <th>Salary Range</th>\n",
       "      <th>Salary Ratio</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Community Health Worker/Patient Services Coord...</td>\n",
       "      <td>Mount Sinai Health Systems</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>20 hours ago</td>\n",
       "      <td>Careers Mount Sinai</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>*missing data*</td>\n",
       "      <td>Qualifications•Bachelor’s Degree•3 Years Healt...</td>\n",
       "      <td>Description\\n\\nThe Community Healthcare Worker...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[17.0, 31.6]</td>\n",
       "      <td>17.0</td>\n",
       "      <td>31.6</td>\n",
       "      <td>$17.00-$31.60</td>\n",
       "      <td>1.9</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sr Renewal Account Manager - Alliance &amp; Partne...</td>\n",
       "      <td>ServiceNow</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>17 hours ago</td>\n",
       "      <td>Built In NYC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>113K–188K a year</td>\n",
       "      <td>Qualifications•7+ years of demonstrated succes...</td>\n",
       "      <td>Company Description\\nAt ServiceNow, our techno...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[$113,400, $187,600]</td>\n",
       "      <td>113000.0</td>\n",
       "      <td>188000.0</td>\n",
       "      <td>$113,000.00-$188,000.00</td>\n",
       "      <td>1.7</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Cost Engineer</td>\n",
       "      <td>MLJ Contracting Corp</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>4 hours ago</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>85K–150K a year</td>\n",
       "      <td>Qualifications•Candidate subject matter expert...</td>\n",
       "      <td>Final compensation will be based on a combinat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>$85,000.00-$150,000.00</td>\n",
       "      <td>1.8</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Policy Partnerships Lead, TBD (Remote)</td>\n",
       "      <td>Block</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>17 hours ago</td>\n",
       "      <td>Built In NYC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>111K–169K a year</td>\n",
       "      <td>Qualifications•You are familiar with decentral...</td>\n",
       "      <td>Company Description\\nFounded in July 2021, TBD...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[$128,500, $157,100, $121,700, $148,700, $110,...</td>\n",
       "      <td>111000.0</td>\n",
       "      <td>169000.0</td>\n",
       "      <td>$111,000.00-$169,000.00</td>\n",
       "      <td>1.5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Director, Operations (Leagues Cup)</td>\n",
       "      <td>Major League Soccer</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>12 hours ago</td>\n",
       "      <td>Ladders</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-time and Part-time</td>\n",
       "      <td>100K–150K a year</td>\n",
       "      <td>Qualifications•Bachelor’s Degree in Sports Man...</td>\n",
       "      <td>Overview\\n\\nThe Director, Leagues Cup Operatio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[$115,000, $130,000, $500]</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>$100,000.00-$150,000.00</td>\n",
       "      <td>1.5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Associate Dev Ops Engineer</td>\n",
       "      <td>Scholastic</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>2 hours ago</td>\n",
       "      <td>SimplyHired</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>58.5K–93.5K a year</td>\n",
       "      <td>Qualifications•HOW YOU CAN FIT (Qualifications...</td>\n",
       "      <td>Job Description:\\n\\nTHE OPPORTUNITY...\\n\\nScho...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>58500.0</td>\n",
       "      <td>93500.0</td>\n",
       "      <td>$58,500.00-$93,500.00</td>\n",
       "      <td>1.6</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Electrical Testing Group Leader - Now Hiring</td>\n",
       "      <td>Bala Consulting Engineers</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>14 hours ago</td>\n",
       "      <td>Snagajob</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-time and Part-time</td>\n",
       "      <td>16.92–29.47 an hour</td>\n",
       "      <td>Qualifications•Suitable candidates need to pos...</td>\n",
       "      <td>Bala Consulting Engineers is a 200-person engi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>16.92</td>\n",
       "      <td>29.47</td>\n",
       "      <td>$16.92-$29.47</td>\n",
       "      <td>1.7</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>988 Contracts Manager</td>\n",
       "      <td>Vibrant Emotional Health</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>14 hours ago</td>\n",
       "      <td>Snagajob</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-time and Part-time</td>\n",
       "      <td>42.54–82.85 an hour</td>\n",
       "      <td>Qualifications•Excellent verbal, written, and ...</td>\n",
       "      <td>Position:\\n\\n988 Contracts Manager...\\n\\nLocat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>42.54</td>\n",
       "      <td>82.85</td>\n",
       "      <td>$42.54-$82.85</td>\n",
       "      <td>1.9</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Release of information</td>\n",
       "      <td>Nuvance Health</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>20 hours ago</td>\n",
       "      <td>Talent.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>*missing data*</td>\n",
       "      <td>Responsibilities•This position is responsible ...</td>\n",
       "      <td>Summary :\\n\\nThis position is responsible for ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[$18.3900, $34.1400]</td>\n",
       "      <td>18.39</td>\n",
       "      <td>34.14</td>\n",
       "      <td>$18.39-$34.14</td>\n",
       "      <td>1.9</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>VP, Email Campaign Operations</td>\n",
       "      <td>Morgan Stanley</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>14 hours ago</td>\n",
       "      <td>ZipRecruiter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>100K–180K a year</td>\n",
       "      <td>*missing data*</td>\n",
       "      <td>*missing data*</td>\n",
       "      <td>VP, Email Campaign Operations SUMMARY We're lo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[$100,000, $180,000]</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>$100,000.00-$180,000.00</td>\n",
       "      <td>1.8</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Technical Solutions Architect - Security - Now...</td>\n",
       "      <td>Cisco Systems, Inc.</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>14 hours ago</td>\n",
       "      <td>Snagajob</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-time and Part-time</td>\n",
       "      <td>39.47–68.67 an hour</td>\n",
       "      <td>Qualifications•You are an aggressive starter, ...</td>\n",
       "      <td>Location: Anywhere, Northeast, U.S.\\nThe #1 pl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>39.47</td>\n",
       "      <td>68.67</td>\n",
       "      <td>$39.47-$68.67</td>\n",
       "      <td>1.7</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Reimbursement Specialist</td>\n",
       "      <td>PROGYNY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>14 hours ago</td>\n",
       "      <td>Snagajob</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-time and Part-time</td>\n",
       "      <td>15.27–23.75 an hour</td>\n",
       "      <td>Qualifications•Strong attention to detail is m...</td>\n",
       "      <td>Thank you for considering Progyny!\\n\\nWe are l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[$65,000, $75,000]</td>\n",
       "      <td>15.27</td>\n",
       "      <td>23.75</td>\n",
       "      <td>$15.27-$23.75</td>\n",
       "      <td>1.6</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Global Surge Team Roster: Fraud Prevention Adv...</td>\n",
       "      <td>International Rescue Committee</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>14 hours ago</td>\n",
       "      <td>Snagajob</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-time and Part-time</td>\n",
       "      <td>59.80–110.67 an hour</td>\n",
       "      <td>Qualifications•6+ years of experience in worki...</td>\n",
       "      <td>Requisition ID: req41763\\n\\nJob Title: Global ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>59.8</td>\n",
       "      <td>110.67</td>\n",
       "      <td>$59.80-$110.67</td>\n",
       "      <td>1.9</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Specialist, Fundraising Support</td>\n",
       "      <td>National Multiple Sclerosis Society</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>14 hours ago</td>\n",
       "      <td>Snagajob</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-time and Part-time</td>\n",
       "      <td>48.35–110.45 an hour</td>\n",
       "      <td>Responsibilities•This position is responsible ...</td>\n",
       "      <td>The National Multiple Sclerosis Society mobili...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>48.35</td>\n",
       "      <td>110.45</td>\n",
       "      <td>$48.35-$110.45</td>\n",
       "      <td>2.3</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>Munichain</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>22 hours ago</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Contractor</td>\n",
       "      <td>*missing data*</td>\n",
       "      <td>Qualifications•C#/Blazor•HTML/TailwindCSS•Azur...</td>\n",
       "      <td>Munichain offers modern and accessible workflo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[$80,000, $120,000]</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>$80,000.00-$120,000.00</td>\n",
       "      <td>1.5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>Senior Associate, Integrated Media Planning</td>\n",
       "      <td>OMD USA</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>24 hours ago</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>*missing data*</td>\n",
       "      <td>Qualifications•Graduate of a four-year college...</td>\n",
       "      <td>Overview\\n\\nMOST CREATIVE MEDIA AGENCY NETWORK...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[$40,000, $70,000]</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>$40,000.00-$70,000.00</td>\n",
       "      <td>1.8</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Special agent</td>\n",
       "      <td>FBI</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>21 hours ago</td>\n",
       "      <td>Talent.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>*missing data*</td>\n",
       "      <td>Qualifications•College transcripts, if qualify...</td>\n",
       "      <td>HOW TO APPLY\\n\\nSTEP 1 : Click on the Apply bu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[$78,000.00, $153,000.00]</td>\n",
       "      <td>78000.0</td>\n",
       "      <td>153000.0</td>\n",
       "      <td>$78,000.00-$153,000.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>It developer</td>\n",
       "      <td>myGwork</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>21 hours ago</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>*missing data*</td>\n",
       "      <td>Qualifications•Undergraduate Degree or Technic...</td>\n",
       "      <td>Hours\\n\\nPay Range...\\n\\n$74,000 - $139,000 an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[$74,000, $139,000]</td>\n",
       "      <td>74000.0</td>\n",
       "      <td>139000.0</td>\n",
       "      <td>$74,000.00-$139,000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Ultrasound Technician</td>\n",
       "      <td>RadNet</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>21 hours ago</td>\n",
       "      <td>ZipRecruiter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>*missing data*</td>\n",
       "      <td>Qualifications•Applicants must have completed ...</td>\n",
       "      <td>Job Description\\n\\nWe invite you to come join ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[$30, $50.41]</td>\n",
       "      <td>30.0</td>\n",
       "      <td>50.41</td>\n",
       "      <td>$30.00-$50.41</td>\n",
       "      <td>1.7</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Account Executive (Professional Information Bu...</td>\n",
       "      <td>Dow Jones</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>22 hours ago</td>\n",
       "      <td>Dow Jones Jobs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>*missing data*</td>\n",
       "      <td>Qualifications•An ability to develop and imple...</td>\n",
       "      <td>Job Description:About us:\\n\\nDow Jones is a gl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[$50,000, $180,000]</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>$50,000.00-$180,000.00</td>\n",
       "      <td>3.6</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Role  \\\n",
       "0    Community Health Worker/Patient Services Coord...   \n",
       "7    Sr Renewal Account Manager - Alliance & Partne...   \n",
       "15                                       Cost Engineer   \n",
       "21              Policy Partnerships Lead, TBD (Remote)   \n",
       "26                  Director, Operations (Leagues Cup)   \n",
       "68                          Associate Dev Ops Engineer   \n",
       "91        Electrical Testing Group Leader - Now Hiring   \n",
       "108                              988 Contracts Manager   \n",
       "109                             Release of information   \n",
       "110                      VP, Email Campaign Operations   \n",
       "115  Technical Solutions Architect - Security - Now...   \n",
       "118                           Reimbursement Specialist   \n",
       "122  Global Surge Team Roster: Fraud Prevention Adv...   \n",
       "127                    Specialist, Fundraising Support   \n",
       "141                                  Software Engineer   \n",
       "164        Senior Associate, Integrated Media Planning   \n",
       "165                                      Special agent   \n",
       "175                                       It developer   \n",
       "177                              Ultrasound Technician   \n",
       "180  Account Executive (Professional Information Bu...   \n",
       "\n",
       "                                 Company      Location        Posted  \\\n",
       "0             Mount Sinai Health Systems  New York, NY  20 hours ago   \n",
       "7                             ServiceNow  New York, NY  17 hours ago   \n",
       "15                  MLJ Contracting Corp  New York, NY   4 hours ago   \n",
       "21                                 Block      Anywhere  17 hours ago   \n",
       "26                   Major League Soccer  New York, NY  12 hours ago   \n",
       "68                            Scholastic  New York, NY   2 hours ago   \n",
       "91             Bala Consulting Engineers  New York, NY  14 hours ago   \n",
       "108             Vibrant Emotional Health  New York, NY  14 hours ago   \n",
       "109                       Nuvance Health  New York, NY  20 hours ago   \n",
       "110                       Morgan Stanley  New York, NY  14 hours ago   \n",
       "115                  Cisco Systems, Inc.  New York, NY  14 hours ago   \n",
       "118                              PROGYNY  New York, NY  14 hours ago   \n",
       "122       International Rescue Committee  New York, NY  14 hours ago   \n",
       "127  National Multiple Sclerosis Society  New York, NY  14 hours ago   \n",
       "141                            Munichain  New York, NY  22 hours ago   \n",
       "164                              OMD USA  New York, NY  24 hours ago   \n",
       "165                                  FBI  New York, NY  21 hours ago   \n",
       "175                              myGwork  New York, NY  21 hours ago   \n",
       "177                               RadNet  New York, NY  21 hours ago   \n",
       "180                            Dow Jones  New York, NY  22 hours ago   \n",
       "\n",
       "                  Source All Sources Listed         Full / Part Time  \\\n",
       "0    Careers Mount Sinai                NaN                Full-time   \n",
       "7           Built In NYC                NaN                Full-time   \n",
       "15              LinkedIn                NaN                Full-time   \n",
       "21          Built In NYC                NaN                Full-time   \n",
       "26               Ladders                NaN  Full-time and Part-time   \n",
       "68           SimplyHired                NaN                Full-time   \n",
       "91              Snagajob                NaN  Full-time and Part-time   \n",
       "108             Snagajob                NaN  Full-time and Part-time   \n",
       "109           Talent.com                NaN                Full-time   \n",
       "110         ZipRecruiter                NaN                Full-time   \n",
       "115             Snagajob                NaN  Full-time and Part-time   \n",
       "118             Snagajob                NaN  Full-time and Part-time   \n",
       "122             Snagajob                NaN  Full-time and Part-time   \n",
       "127             Snagajob                NaN  Full-time and Part-time   \n",
       "141             LinkedIn                NaN               Contractor   \n",
       "164                                     NaN                            \n",
       "165           Talent.com                NaN                Full-time   \n",
       "175                                     NaN                            \n",
       "177         ZipRecruiter                NaN                Full-time   \n",
       "180       Dow Jones Jobs                NaN                Full-time   \n",
       "\n",
       "           Scraped Salary                                     Job Highlights  \\\n",
       "0          *missing data*  Qualifications•Bachelor’s Degree•3 Years Healt...   \n",
       "7        113K–188K a year  Qualifications•7+ years of demonstrated succes...   \n",
       "15        85K–150K a year  Qualifications•Candidate subject matter expert...   \n",
       "21       111K–169K a year  Qualifications•You are familiar with decentral...   \n",
       "26       100K–150K a year  Qualifications•Bachelor’s Degree in Sports Man...   \n",
       "68     58.5K–93.5K a year  Qualifications•HOW YOU CAN FIT (Qualifications...   \n",
       "91    16.92–29.47 an hour  Qualifications•Suitable candidates need to pos...   \n",
       "108   42.54–82.85 an hour  Qualifications•Excellent verbal, written, and ...   \n",
       "109        *missing data*  Responsibilities•This position is responsible ...   \n",
       "110      100K–180K a year                                     *missing data*   \n",
       "115   39.47–68.67 an hour  Qualifications•You are an aggressive starter, ...   \n",
       "118   15.27–23.75 an hour  Qualifications•Strong attention to detail is m...   \n",
       "122  59.80–110.67 an hour  Qualifications•6+ years of experience in worki...   \n",
       "127  48.35–110.45 an hour  Responsibilities•This position is responsible ...   \n",
       "141        *missing data*  Qualifications•C#/Blazor•HTML/TailwindCSS•Azur...   \n",
       "164        *missing data*  Qualifications•Graduate of a four-year college...   \n",
       "165        *missing data*  Qualifications•College transcripts, if qualify...   \n",
       "175        *missing data*  Qualifications•Undergraduate Degree or Technic...   \n",
       "177        *missing data*  Qualifications•Applicants must have completed ...   \n",
       "180        *missing data*  Qualifications•An ability to develop and imple...   \n",
       "\n",
       "                                       Job Description  \\\n",
       "0    Description\\n\\nThe Community Healthcare Worker...   \n",
       "7    Company Description\\nAt ServiceNow, our techno...   \n",
       "15   Final compensation will be based on a combinat...   \n",
       "21   Company Description\\nFounded in July 2021, TBD...   \n",
       "26   Overview\\n\\nThe Director, Leagues Cup Operatio...   \n",
       "68   Job Description:\\n\\nTHE OPPORTUNITY...\\n\\nScho...   \n",
       "91   Bala Consulting Engineers is a 200-person engi...   \n",
       "108  Position:\\n\\n988 Contracts Manager...\\n\\nLocat...   \n",
       "109  Summary :\\n\\nThis position is responsible for ...   \n",
       "110                                     *missing data*   \n",
       "115  Location: Anywhere, Northeast, U.S.\\nThe #1 pl...   \n",
       "118  Thank you for considering Progyny!\\n\\nWe are l...   \n",
       "122  Requisition ID: req41763\\n\\nJob Title: Global ...   \n",
       "127  The National Multiple Sclerosis Society mobili...   \n",
       "141  Munichain offers modern and accessible workflo...   \n",
       "164  Overview\\n\\nMOST CREATIVE MEDIA AGENCY NETWORK...   \n",
       "165  HOW TO APPLY\\n\\nSTEP 1 : Click on the Apply bu...   \n",
       "175  Hours\\n\\nPay Range...\\n\\n$74,000 - $139,000 an...   \n",
       "177  Job Description\\n\\nWe invite you to come join ...   \n",
       "180  Job Description:About us:\\n\\nDow Jones is a gl...   \n",
       "\n",
       "                                        Any Other Text Date Scraped  \\\n",
       "0                                                  NaN          NaN   \n",
       "7                                                  NaN          NaN   \n",
       "15                                                 NaN          NaN   \n",
       "21                                                 NaN          NaN   \n",
       "26                                                 NaN          NaN   \n",
       "68                                                 NaN          NaN   \n",
       "91                                                 NaN          NaN   \n",
       "108                                                NaN          NaN   \n",
       "109                                                NaN          NaN   \n",
       "110  VP, Email Campaign Operations SUMMARY We're lo...          NaN   \n",
       "115                                                NaN          NaN   \n",
       "118                                                NaN          NaN   \n",
       "122                                                NaN          NaN   \n",
       "127                                                NaN          NaN   \n",
       "141                                                NaN          NaN   \n",
       "164                                                NaN          NaN   \n",
       "165                                                NaN          NaN   \n",
       "175                                                NaN          NaN   \n",
       "177                                                NaN          NaN   \n",
       "180                                                NaN          NaN   \n",
       "\n",
       "                                      Salary From Text Salary Lower Bound  \\\n",
       "0                                         [17.0, 31.6]               17.0   \n",
       "7                                 [$113,400, $187,600]           113000.0   \n",
       "15                                                  []            85000.0   \n",
       "21   [$128,500, $157,100, $121,700, $148,700, $110,...           111000.0   \n",
       "26                          [$115,000, $130,000, $500]           100000.0   \n",
       "68                                                  []            58500.0   \n",
       "91                                                  []              16.92   \n",
       "108                                                 []              42.54   \n",
       "109                               [$18.3900, $34.1400]              18.39   \n",
       "110                               [$100,000, $180,000]           100000.0   \n",
       "115                                                 []              39.47   \n",
       "118                                 [$65,000, $75,000]              15.27   \n",
       "122                                                 []               59.8   \n",
       "127                                                 []              48.35   \n",
       "141                                [$80,000, $120,000]            80000.0   \n",
       "164                                 [$40,000, $70,000]            40000.0   \n",
       "165                          [$78,000.00, $153,000.00]            78000.0   \n",
       "175                                [$74,000, $139,000]            74000.0   \n",
       "177                                      [$30, $50.41]               30.0   \n",
       "180                                [$50,000, $180,000]            50000.0   \n",
       "\n",
       "    Salary Upper Bound             Salary Range Salary Ratio Notes  \n",
       "0                 31.6            $17.00-$31.60          1.9        \n",
       "7             188000.0  $113,000.00-$188,000.00          1.7        \n",
       "15            150000.0   $85,000.00-$150,000.00          1.8        \n",
       "21            169000.0  $111,000.00-$169,000.00          1.5        \n",
       "26            150000.0  $100,000.00-$150,000.00          1.5        \n",
       "68             93500.0    $58,500.00-$93,500.00          1.6        \n",
       "91               29.47            $16.92-$29.47          1.7        \n",
       "108              82.85            $42.54-$82.85          1.9        \n",
       "109              34.14            $18.39-$34.14          1.9        \n",
       "110           180000.0  $100,000.00-$180,000.00          1.8        \n",
       "115              68.67            $39.47-$68.67          1.7        \n",
       "118              23.75            $15.27-$23.75          1.6        \n",
       "122             110.67           $59.80-$110.67          1.9        \n",
       "127             110.45           $48.35-$110.45          2.3        \n",
       "141           120000.0   $80,000.00-$120,000.00          1.5        \n",
       "164            70000.0    $40,000.00-$70,000.00          1.8        \n",
       "165           153000.0   $78,000.00-$153,000.00          2.0        \n",
       "175           139000.0   $74,000.00-$139,000.00          1.9        \n",
       "177              50.41            $30.00-$50.41          1.7        \n",
       "180           180000.0   $50,000.00-$180,000.00          3.6        "
      ]
     },
     "execution_count": 1892,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample of job postings with salary ratio in top 75%\n",
    "\n",
    "google_jobs_with_salaries[google_jobs_with_salaries['Salary Ratio'] > 1.4].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146d8fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outstanding issues:\n",
    "\n",
    "# investigate duplicates to make sure all are removed\n",
    "# index 120: '$50 billion' gets counted as a $50 salary when it's really talking about the industry/ company\n",
    "    # check if item in list after the number is in a list of words like Bil, M, billion etc\n",
    "# index 36: $130,000.00 - 150,000.00 will not pull second value\n",
    "# index ?: ['RATE...\\n\\n$15', '20/hr\\n\\nPOSITION'] -> becomes .15 instead of 15 (throwing off ratio)\n",
    "    # maybe only keep period if a number proceeds and follows it -> #.#\n",
    "\n",
    "# index 3619: Pay range: (USD)31.12 hrly -(USD)64.80 hrly not being picked up as salary\n",
    "# index 30: salary in title, not being found\n",
    "# index 100: when user adds K to the end of an unabbreviated number... maybe not worth trying to fix cause pretty rare error\n",
    "# index 139: user error entry, adding extra 0 to one entry... not really worth automating this away, maybe just have \n",
    "    # to find outliers and manually correct or drop once data is collected\n",
    "# consider sitation where bonus is listed along with single salary number... would be inaccurate\n",
    "# there are false positive cases like when just a bonus is included\n",
    "    # remove numbers that much smaller than the rest/ average?\n",
    "\n",
    "## ^ for these issues, maybe just look at entries with really weird ratios or \"salary ambiguous\" tags and manually fix them\n",
    "\n",
    "# fixed issues:\n",
    "\n",
    "# index 114: when lower bound is higher than upper bound -> fixed by sorting the list\n",
    "# lists that are more than 2 items long (for both functions) -> right now, addressed by saying \"salary ambiguous\"\n",
    "# index 118: \n",
    "    # $80,000-$90,000/ year plus commissions and incentives in the range of $20,000-$30,000/ year\n",
    "    # Ouput: 8000090000.0 - 2000030000.0\n",
    "    # right now, addressed by saying \"salary ambiguous\"\n",
    "# index 65: [1,800, $118,000—$210,000] leads to 1800.0 and 118000210000.0 \n",
    "    # weirdly there are two kinds of '—' it seems despite them looking indentical, so just added the extra one in\n",
    "# index 3 and others: sorts alphabetically, not numerically \n",
    "    # sorted(scraped_df['Salary From Description'][3])[0]\n",
    "# index 120: $50MM+ gets counted as a salary when it's really talking about the industry/ company\n",
    "    # remove all numbers that contain m or b\n",
    "# index 1, 11: cases where salary range (or just single salary) is repeated twice labeled as ambiguous\n",
    "    # remove duplicates from lists (round all of them to avoid decimal issues)\n",
    "    # this could help if scanning Job Highlights and Descriptions in one go as well\n",
    "# index ?: if $130,000.00- $150,000.00 or $130,000.00 -$150,000.00 will be deemed ambiguous\n",
    "    # use method saved below to break numbers up, and if the result is still just two numbers, use them, if not, deem ambiguous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56958633",
   "metadata": {},
   "source": [
    "## Old Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92e7568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # url filters: jobs posted within past day, within 15 miles of New York, NY\n",
    "# google_jobs_url = 'https://www.google.com/search?q=jobs&oq=google+jobs+data+analyst&aqs=chrome..69i57j69i59j0i512j0i22i30i625l4j69i60.4543j0j7&sourceid=chrome&ie=UTF-8&ibp=htl;jobs&sa=X&ved=2ahUKEwjXsv-_iZP9AhVPRmwGHX5xDEsQutcGKAF6BAgPEAU&sxsrf=AJOqlzWGHNISzgpAUCZBmQA1mWXXt3I7gA:1676311105893#fpstate=tldetail&htivrt=jobs&htichips=city:Owg_06VPwoli_nfhBo8LyA%3D%3D,date_posted:today&htischips=city;Owg_06VPwoli_nfhBo8LyA%3D%3D:New%20York_comma_%20NY,date_posted;today&htilrad=24.1401&htidocid=9dwQD_uVzp1Nu-9BAAAAAA%3D%3D'\n",
    "# # path to CSV where google jobs dataset will be held\n",
    "# google_jobs_df_path = '/Users/ravram/Desktop/pay-transparency/data/output/google-jobs-cronjob.csv' # need to change path when put on server\n",
    "# # path to CSV where extra column data will be held\n",
    "# extra_columns_df_path = '/Users/ravram/Desktop/pay-transparency/data/output/google-jobs-extra-cols-cronjob.csv' # need to change path when put on server\n",
    "\n",
    "# def scrape_google_jobs(url, final_path_location, postings):\n",
    "    \n",
    "# # url: web url to the google jobs page that will be scraped (str)\n",
    "# # final_path_location: path to the CSV file where the scraped data will be stored (str)\n",
    "# # postings: number of job postings to be scraped -> can be increased by increments of 10 starting at 20, going up to limit of 150 (int)\n",
    "    \n",
    "#     options = Options() # preparing to run in headless browser\n",
    "#     options.add_argument('headless') \n",
    "\n",
    "#     # using sing selenium to launch and scroll through the Google Jobs page\n",
    "#     url = url\n",
    "#     driver = webdriver.Chrome(options=options)\n",
    "    \n",
    "#     user_agent = driver.execute_script(\"return navigator.userAgent;\")\n",
    "#     user_agent = user_agent.replace(\"HeadlessChrome\",\"Chrome\")\n",
    "#     driver.execute_cdp_cmd('Network.setUserAgentOverride',{\"userAgent\": f'{user_agent}'})\n",
    "    \n",
    "#     driver.get(url)\n",
    "\n",
    "#     # column names and paths to desired data\n",
    "#     xpaths = { \n",
    "#      'Role'            :\"./div/div[1]/div/div[1]/h2\",\n",
    "#      'Company'         :\"./div/div[1]/div/div[2]/div[2]/div[1]\",\n",
    "#      'Location'        :\"./div/div[1]/div/div[2]/div[2]/div[2]\",\n",
    "#      'Posted'          :\"./div/div[3]/div[1]/span[2]/span\",\n",
    "#      'Scraped Salary'  :\".//span[@class='LL4CDc' and contains(@aria-label,'Salary')]/span\",\n",
    "#      'Job Highlights'  :\"./div/div[4]/div[1]/div[2]/g-expandable-container/div/g-expandable-content[2]/span\",\n",
    "#      'Job Description' :\"./div/div[5]/div/span\",\n",
    "#      'Any Other Text'  :\"./div/div[4]\" \n",
    "#     }\n",
    "    \n",
    "#     scrolls_to_do = postings # setting number of job postings to be scraped\n",
    "#     scrolls_done = 0\n",
    "#     data = {key:[] for key in xpaths} # data will be added to this dict\n",
    "    \n",
    "#     # stay in while loop until desired number of postings have been scrolled to\n",
    "#     while scrolls_done < scrolls_to_do: \n",
    "#         lis_scr = driver.find_elements(By.XPATH, \"//li[@data-ved]//div[@role='treeitem']/div/div\") # path to section of page where user can scroll through job postings \n",
    "#         #print('lis length=',len(lis_scr), f'{scrolls_done=}', end='\\r')\n",
    "        \n",
    "#         if (len(lis_scr) == scrolls_done) and (scrolls_to_do - scrolls_done) > 0: # in case the postings variable exceeds number of available job posting entries (otherwise code will be stuck in infinite loop)\n",
    "        \n",
    "#             print('\\nNote: requested # of postings greater than available postings')\n",
    "#             scrolls_to_do = len(lis_scr) # resetting scrolls_to_do to the max length of lis_scr so can break out of while loop\n",
    "            \n",
    "#         # scrolling down the page to make desired number of job postings load, therefore making them accessible for scraping\n",
    "#         for li_scr in lis_scr[scrolls_done:]:\n",
    "#             driver.execute_script('arguments[0].scrollIntoView({block: \"center\", behavior: \"smooth\"});', li_scr) \n",
    "\n",
    "#             scrolls_done += 1\n",
    "#             print(f'{scrolls_done=}', end='\\r') # to visualize how many scrolls have been performed\n",
    "#             time.sleep(.2)     \n",
    "    \n",
    "#     lis_descr = driver.find_elements(By.XPATH, \"//*[@id='gws-plugins-horizon-jobs__job_details_page']\") # path to description page for each job\n",
    "    \n",
    "#     print('')\n",
    "#     jobs_done = 0 \n",
    "    \n",
    "#     for li_descr in lis_descr[0:scrolls_to_do]: # looping through desired number of job description pages, which is where the data will be pulled from\n",
    "    \n",
    "#         for key in xpaths:\n",
    "\n",
    "#             try: # pull data at each path in the xpaths dict for each job posting\n",
    "#                 t = li_descr.find_element(By.XPATH, xpaths[key]).get_attribute('innerText')\n",
    "#             except NoSuchElementException: # if can't find, indicate with text\n",
    "#                 t = '*missing data*'\n",
    "#             if t == '': # in cases where element exists but is just ''\n",
    "#                 t='*missing data*'\n",
    "                \n",
    "#             data[key].append(t) # add to data dict\n",
    "            \n",
    "#         jobs_done += 1\n",
    "#         print(f'{jobs_done=}', end='\\r') # to visualize how many jobs have been completed\n",
    "#         time.sleep(.2)\n",
    "\n",
    "#     scraped_df = pd.DataFrame(data) # convert to df\n",
    "    \n",
    "#     for ind in scraped_df.index: # Any Other Text collects full text for posting... only worth keeping if Job Highlights and Description are empty, otherwise redundant info just taking up space\n",
    "        \n",
    "#         if (scraped_df['Job Highlights'][ind] != '*missing data*') and (scraped_df['Job Description'][ind] != '*missing data*'):\n",
    "            \n",
    "#             scraped_df.loc[ind, 'Any Other Text'] = np.nan # erasing this text if either Job Highlights or Description is present\n",
    "    \n",
    "#     path = final_path_location \n",
    "    \n",
    "#     if os.path.exists(path): # if CSV already exists at the specified path, add the new data found in scraped_df \n",
    "#         original_df = pd.read_csv(path) # convert existing CSV to df\n",
    "#         original_df = pd.concat([original_df,scraped_df]) # add new data\n",
    "#         original_df = original_df.drop_duplicates(subset=['Role','Company','Location','Scraped Salary','Job Highlights','Job Description', 'Any Other Text']) # drop entries with identical data in these columns... leaving Posted out of this in case duplicates are posted at dif times\n",
    "#         original_df.to_csv(path, index = False) # redownloading updated df to the specified path\n",
    "#     else: # otherwise, create new file at this path (for first time function is run)\n",
    "#         scraped_df.to_csv(path, index = False)\n",
    "    \n",
    "#     return \n",
    "\n",
    "# scrape_google_jobs(google_jobs_url, google_jobs_df_path, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a2911e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_salaries(df, col_name):\n",
    "    \n",
    "#     salary_from_col = 'Salary From ' + col_name\n",
    "    \n",
    "#     df[salary_from_col] = '' # creating column where salaries found in description will be placed\n",
    "#     df['Salary Lower Bound'] = '' # lower bound\n",
    "#     df['Salary Upper Bound'] = '' # upper bound\n",
    "    \n",
    "#     for ind in df.index: # iterating through the descriptions for each job\n",
    "\n",
    "#         salary_list = []\n",
    "\n",
    "#         phrase = df[col_name][ind] # text in description\n",
    "#         phrase = phrase.replace('•',' ') # eliminating bullet points\n",
    "#         phrase_to_list = phrase.split(\" \") # creating list of all strings in the description\n",
    "\n",
    "#         for i in range(len(phrase_to_list)): # iterating through phrase_to_list\n",
    "\n",
    "#             if len(phrase_to_list[i]) > 0: # otherwise -1 index will break code\n",
    "                \n",
    "#                 if phrase_to_list[i] not in ['401K', '401k']: # eliminating '401K' so doesn't get labeled as salary\n",
    "                    \n",
    "#                     if not [True if e in phrase_to_list[i].lower() else False for e in ['b','m']][0]: # weeding out cases like '$10b industry' or '$3M company'\n",
    "                    \n",
    "#                         if ('$' in phrase_to_list[i]) or ('k' == phrase_to_list[i][-1].lower() and phrase_to_list[i][-2].isdigit()): # looking for salary indicators\n",
    "\n",
    "#                             salary_list.append(phrase_to_list[i]) # adding strings with salary indicators to ongoing list\n",
    "\n",
    "#                         if phrase_to_list[i] == '$' and phrase_to_list[i+1][0].isdigit(): # if there's a space between $ and number\n",
    "\n",
    "#                             salary_list.append(phrase_to_list[i+1]) # add the subsequent list item in this case\n",
    "\n",
    "#                         df[salary_from_col][ind] = salary_list # place in this new column\n",
    "          \n",
    "#         # now that salaries are collected from the description, creating lower and upper bounds based on given info\n",
    "                \n",
    "#         if df['Scraped Salary'][ind] == '*missing data*': # if salary not initially scraped\n",
    "            \n",
    "#             if df['Salary From ' + col_name][ind] == []: # if no salary found in description\n",
    "        \n",
    "#                 df['Salary Lower Bound'][ind] = '*no salary found*'\n",
    "#                 df['Salary Upper Bound'][ind] = '*no salary found*'\n",
    "            \n",
    "#             else: # if salary is found in the description\n",
    "                \n",
    "#                 # if first value is just $, remove so doesn't affect making the range (cases where there's originally a space between $ and number)\n",
    "                \n",
    "#                 for i in df[salary_from_col][ind]:\n",
    "#                     if i == '$':\n",
    "#                         df[salary_from_col][ind].remove('$') \n",
    "                        \n",
    "#                 desc_sal_list = [] # in cases where there are two \"numbers\" that are really 1-2 ranges -> [20K-30K,5K-6K] or [20K,15K-16K]\n",
    "                    \n",
    "#                 for i in range(len(df[salary_from_col][ind])): # removing the dashes and isolating all of the individual numbers\n",
    "\n",
    "#                     if '–' in df[salary_from_col][ind][i]: \n",
    "#                         desc_sal = df[salary_from_col][ind][i].replace('–', ' ')\n",
    "#                     if '—' in df[salary_from_col][ind][i]: \n",
    "#                         desc_sal = df[salary_from_col][ind][i].replace('—', ' ')\n",
    "#                     elif '-' in df[salary_from_col][ind][i]:\n",
    "#                         desc_sal = df[salary_from_col][ind][i].replace('-', ' ')\n",
    "#                     else:\n",
    "#                         desc_sal = df[salary_from_col][ind][i]\n",
    "\n",
    "#                     desc_sal_list = desc_sal_list + desc_sal.split(' ')\n",
    "\n",
    "#                     if '' in desc_sal_list: desc_sal_list.remove('')\n",
    "                        \n",
    "#                 df[salary_from_col][ind] = desc_sal_list\n",
    "                \n",
    "#                 # attempting to preemptively correct cases that would otherwise trigger 'salary ambiguous' label so that they can be properly processed\n",
    "                \n",
    "#                 if len(df[salary_from_col][ind]) > 2: # when length of list > 2, will be marked ambiguous unless corrected first\n",
    "                    \n",
    "#                     df[salary_from_col][ind] = clean_salary_ambiguous(df[salary_from_col][ind]) \n",
    "                            \n",
    "#                 # now that all the lists are cleaned, proceed to determine salary ranges:\n",
    "                \n",
    "#                 if len(df[salary_from_col][ind]) > 2: # if multiple numbers are still found after cleaning, hard to tell what salary range is, will be marked ambiguous\n",
    "                    \n",
    "#                     df['Salary Lower Bound'][ind] = '*salary ambiguous*'\n",
    "#                     df['Salary Upper Bound'][ind] = '*salary ambiguous*'\n",
    "                \n",
    "#                 if len(df[salary_from_col][ind]) == 2: # if two entries provided, create salary range\n",
    "                    \n",
    "#                     df['Salary Lower Bound'][ind] = df[salary_from_col][ind][0] \n",
    "#                     df['Salary Upper Bound'][ind] = df[salary_from_col][ind][1]\n",
    "                \n",
    "#                 elif len(df[salary_from_col][ind]) == 1: # one entry\n",
    "                                          \n",
    "#                     df['Salary Lower Bound'][ind] = df[salary_from_col][ind][0] \n",
    "                          \n",
    "#         else: # if salary found in initial scrape, use it as final salary \n",
    "            \n",
    "#             if '–' in df['Scraped Salary'][ind]: # removing dashes\n",
    "#                 scraped_sal = df['Scraped Salary'][ind].replace('–', ' ')\n",
    "#             elif '—' in df['Scraped Salary'][ind]: # removing dashes\n",
    "#                 scraped_sal = df['Scraped Salary'][ind].replace('—', ' ')\n",
    "#             elif '-' in df['Scraped Salary'][ind]: # removing dashes\n",
    "#                 scraped_sal = df['Scraped Salary'][ind].replace('-', ' ')\n",
    "#             else:\n",
    "#                 scraped_sal = df['Scraped Salary'][ind]\n",
    "                \n",
    "#             scraped_sal_list = scraped_sal.split(' ') # seperating into list of strings\n",
    "            \n",
    "#             df['Salary Lower Bound'][ind] = scraped_sal_list[0] # first number\n",
    "#             df['Salary Upper Bound'][ind] = scraped_sal_list[1] # second number\n",
    "\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1d67c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scrape_extra_columns(url, final_path_location, postings):\n",
    "    \n",
    "# # url: web url to the google jobs page that will be scraped (str)\n",
    "# # final_path_location: path to the CSV file where the scraped data will be stored (str)\n",
    "# # postings: number of job postings to be scraped -> can be increased by increments of 10 starting at 20, going up to limit of 150 (int)\n",
    "    \n",
    "#     options = Options() # preparing to run in headless browser\n",
    "#     options.add_argument('headless')\n",
    "\n",
    "#     # using sing selenium to launch and scroll through the Google Jobs page\n",
    "#     url = url\n",
    "#     driver = webdriver.Chrome(options=options)\n",
    "    \n",
    "#     user_agent = driver.execute_script(\"return navigator.userAgent;\")\n",
    "#     user_agent = user_agent.replace(\"HeadlessChrome\",\"Chrome\")\n",
    "#     driver.execute_cdp_cmd('Network.setUserAgentOverride',{\"userAgent\": f'{user_agent}'})\n",
    "    \n",
    "#     driver.get(url)\n",
    "\n",
    "#     # column names and paths to desired data\n",
    "#     xpaths = {\n",
    "#      'Role'            :\"./div[2]\",\n",
    "#      'Company'         :\"./div[4]/div/div[1]\",\n",
    "#      'Source'          :\"./div[4]/div/div[3]\",\n",
    "#      'Full / Part Time':\".//*[name()='path'][contains(@d,'M20 6')]/ancestor::div[1]\",\n",
    "#     }\n",
    "    \n",
    "#     jobs_to_do = postings # setting number of job postings to be scraped\n",
    "#     jobs_done = 0\n",
    "#     data = {key:[] for key in xpaths} # data will be added to this dict\n",
    "\n",
    "#     # stay in while loop until desired number of postings have been scrolled to and scraped \n",
    "#     while jobs_done < jobs_to_do: \n",
    "#         lis = driver.find_elements(By.XPATH, \"//li[@data-ved]//div[@role='treeitem']/div/div\") # path to section of page where user can scroll through job postings \n",
    "#         # print('lis length=',len(lis), f'{jobs_done=}', end='\\r')\n",
    "        \n",
    "#         if (len(lis) == jobs_done) and (jobs_to_do - jobs_done) > 0: # in case the postings variable exceeds number of available job posting entries (otherwise code will be stuck in infinite loop)\n",
    "        \n",
    "#             print('\\nNote: requested # of postings greater than available postings')\n",
    "#             jobs_to_do = len(lis) # resetting scrolls_to_do to the max length of lis_scr so can break out of while loop\n",
    "        \n",
    "#         # scrolling down the page to make desired number of job postings load, therefore making them accessible for scraping\n",
    "#         for li in lis[jobs_done:]:\n",
    "#             driver.execute_script('arguments[0].scrollIntoView({block: \"center\", behavior: \"smooth\"});', li)\n",
    "\n",
    "#             for key in xpaths:\n",
    "#                 try: # pull data at each path in the xpaths dict for each job posting\n",
    "#                     t = li.find_element(By.XPATH, xpaths[key]).get_attribute('innerText')\n",
    "#                 except NoSuchElementException: # if can't find, indicate with text\n",
    "#                     t = '*missing data*'\n",
    "#                 data[key].append(t) # add to data dict\n",
    "\n",
    "#             jobs_done += 1\n",
    "#             print(f'{jobs_done=}', end='\\r') # to visualize how many jobs have been completed\n",
    "#             time.sleep(.2)\n",
    "            \n",
    "#     cols_to_add = pd.DataFrame(data) # convert to df\n",
    "        \n",
    "#     path = final_path_location \n",
    "    \n",
    "#     if os.path.exists(path): # if CSV already exists at the specified path, add the new data found in scraped_df \n",
    "#         original_df = pd.read_csv(path) # convert existing CSV to df\n",
    "#         original_df = pd.concat([original_df,cols_to_add]) # add new data\n",
    "#         original_df = original_df.drop_duplicates() # drop entries with identical data \n",
    "#         original_df.to_csv(path, index = False) # redownloading updated df to the specified path\n",
    "#     else: # otherwise, create new file at this path (for first time function is run)\n",
    "#         cols_to_add.to_csv(path, index = False)    \n",
    "        \n",
    "#     return \n",
    "\n",
    "# scrape_extra_columns(google_jobs_url, extra_columns_df_path, 150) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "38ddd0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # og method\n",
    "# #def scrape_google_jobs(google_jobs_df):\n",
    "\n",
    "# #using selenium to launch and scroll through the Google Jobs page\n",
    "# url = \"https://www.google.com/search?q=in+new+york+city&oq=google+jobs+data+analyst&aqs=chrome..69i57j69i59j0i512j0i22i30i625l4j69i60.4543j0j7&sourceid=chrome&ie=UTF-8&ibp=htl;jobs&sa=X&ved=2ahUKEwjXsv-_iZP9AhVPRmwGHX5xDEsQutcGKAF6BAgPEAU&sxsrf=AJOqlzWGHNISzgpAUCZBmQA1mWXXt3I7gA:1676311105893#fpstate=tldetail&htivrt=jobs&htidocid=DKwJ4ogc_UrLs-QfAAAAAA%3D%3D\"\n",
    "# driver = webdriver.Chrome()\n",
    "# driver.get(url)\n",
    "\n",
    "# xpaths = {\n",
    "#  #'Logo'            :\"./div[1]//img\",\n",
    "#  'Role'            :\"./div[2]\",\n",
    "#  'Company'         :\"./div[4]/div/div[1]\",\n",
    "#  'Location'        :\"./div[4]/div/div[2]\",\n",
    "#  'Source'          :\"./div[4]/div/div[3]\",\n",
    "#  'Posted'          :\".//*[name()='path'][contains(@d,'M11.99')]/ancestor::div[1]\",\n",
    "#  'Full / Part Time':\".//*[name()='path'][contains(@d,'M20 6')]/ancestor::div[1]\",\n",
    "#  'Salary'          :\".//span[@class='LL4CDc' and contains(@aria-label,'Salary')]/span\"\n",
    "# }\n",
    "\n",
    "# jobs_to_do = 160\n",
    "# jobs_done = 0\n",
    "# data = {key:[] for key in xpaths}\n",
    "\n",
    "# while jobs_done < jobs_to_do:\n",
    "#     lis = driver.find_elements(By.XPATH, \"//li[@data-ved]//div[@role='treeitem']/div/div\")\n",
    "#     print('lis length=',len(lis), f'{jobs_done=}', end='\\r')\n",
    "    \n",
    "#     if (len(lis) == jobs_done) and (jobs_to_do - jobs_done) > 0:\n",
    "        \n",
    "#         print('\\noops')\n",
    "#         jobs_to_do = len(lis)\n",
    "\n",
    "#     for li in lis[jobs_done:]:\n",
    "#         driver.execute_script('arguments[0].scrollIntoView({block: \"center\", behavior: \"smooth\"});', li)\n",
    "\n",
    "#         for key in xpaths:\n",
    "#             try:\n",
    "#                 t = li.find_element(By.XPATH, xpaths[key]).get_attribute('src' if key=='Logo' else 'innerText')\n",
    "#             except NoSuchElementException:\n",
    "#                 t = '*missing data*'\n",
    "#             data[key].append(t)\n",
    "\n",
    "#         jobs_done += 1\n",
    "#         #print(f'{jobs_done=}', end='\\r')\n",
    "#         time.sleep(.2)\n",
    "\n",
    "#         scraped_df = pd.DataFrame(data)\n",
    "\n",
    "# # google_jobs_df = google_jobs_df.append(scraped_df)\n",
    "# # # google_jobs_df = google_jobs_df.drop_duplicates()\n",
    "\n",
    "# #     #return google_jobs_df\n",
    "    \n",
    "# # scraped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "37388765",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from serpapi import GoogleSearch\n",
    "# import json\n",
    "\n",
    "# finding location params for NYC\n",
    "\n",
    "# response = requests.get('https://serpapi.com/locations.json?q=New York&limit=5')\n",
    "# response_list = response.json()\n",
    "\n",
    "# response_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a611652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from serpapi import GoogleSearch\n",
    "\n",
    "# serpapi_key = 'd5ff8cd8814fc2d40478abe398700948378acf0cedd38fa0ceb5c8b1a0bb295a'\n",
    "\n",
    "# params = {\n",
    "#     'api_key': serpapi_key,                                     # https://serpapi.com/manage-api-key\n",
    "#     'chips': 'date_posted:week,city:Owg_06VPwoli_nfhBo8LyA==',  # city = NYC, date_posted:week for all data posted in last week\n",
    "#     'q': 'new york',                                            # search query\n",
    "#     'hl': 'en',                                                 # language of the search\n",
    "#     'engine': 'google_jobs',                                    # SerpApi search engine\n",
    "#     'start': 0                                                  # pagination\n",
    "# }\n",
    "\n",
    "# google_jobs_results = []\n",
    "\n",
    "# while True:\n",
    "#     search = GoogleSearch(params) # where data extraction happens on the SerpApi backend\n",
    "#     result_dict = search.get_dict() # JSON -> Python dict\n",
    "\n",
    "#     if 'error' in result_dict:\n",
    "#         break\n",
    "    \n",
    "#     for result in result_dict['jobs_results']:\n",
    "#         google_jobs_results.append(result)\n",
    "\n",
    "#     # increments 'start' parameter to 10 which will trigger Google Jobs to paginate to the next page\n",
    "#     params['start'] += 10\n",
    "\n",
    "# #print(json.dumps(google_jobs_results, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308dc4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# google_jobs_df = pd.DataFrame(google_jobs_results)\n",
    "# google_jobs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f3d8db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(json.dumps(google_jobs_results, indent=2, ensure_ascii=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
